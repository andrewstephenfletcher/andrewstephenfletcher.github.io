{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e58a023d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b3caae78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f96b8fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clear MPS cache\n",
    "if torch.backends.mps.is_available():\n",
    "    torch.mps.empty_cache()\n",
    "    \n",
    "# Also clear any cached gradients\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f9f6376",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f36c4dbfb3747ea8b9f37639e8786bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Phi3ForCausalLM(\n",
       "  (model): Phi3Model(\n",
       "    (embed_tokens): Embedding(32064, 3072, padding_idx=32000)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x Phi3DecoderLayer(\n",
       "        (self_attn): Phi3Attention(\n",
       "          (o_proj): Linear(in_features=3072, out_features=3072, bias=False)\n",
       "          (qkv_proj): Linear(in_features=3072, out_features=9216, bias=False)\n",
       "        )\n",
       "        (mlp): Phi3MLP(\n",
       "          (gate_up_proj): Linear(in_features=3072, out_features=16384, bias=False)\n",
       "          (down_proj): Linear(in_features=8192, out_features=3072, bias=False)\n",
       "          (activation_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): Phi3RMSNorm((3072,), eps=1e-05)\n",
       "        (post_attention_layernorm): Phi3RMSNorm((3072,), eps=1e-05)\n",
       "        (resid_attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (resid_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (norm): Phi3RMSNorm((3072,), eps=1e-05)\n",
       "    (rotary_emb): Phi3RotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=3072, out_features=32064, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"microsoft/phi-3-mini-4k-instruct\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "691290cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 2000 sequences.\n"
     ]
    }
   ],
   "source": [
    "def generate_dataset(n_samples=1000):\n",
    "\n",
    "    # Simple vocabulary to construct sentences\n",
    "    subjects = [\"The cat\", \"A dog\", \"The car\", \"My friend\", \"The bird\", \"A plane\", \"The code\", \"This model\", \"The robot\", \"A machine\"]\n",
    "    verbs = [\"jumps over\", \"runs to\", \"flies above\", \"looks at\", \"sits on\", \"moves to\", \"likes\", \"sees\", \"devours\", \"builds\"]\n",
    "    things = [\"the fence\", \"the hill\", \"the cloud\", \"the screen\", \"the table\", \"the city\", \"the pizza\", \"the park\", \"the book\", \"the house\"]\n",
    "\n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "    for subject in subjects:\n",
    "        for verb in verbs:\n",
    "            for thing in things:\n",
    "                sequence = subject + \" \" + verb + \" \" + thing\n",
    "                data.append(sequence)\n",
    "                labels.append(0)\n",
    "                data.append(sequence.upper())\n",
    "                labels.append(1)\n",
    "\n",
    "    return data, labels\n",
    "\n",
    "dataset,labels = generate_dataset()\n",
    "labels = torch.tensor(labels)\n",
    "\n",
    "print(f\"Generated {len(dataset)} sequences.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cea0a23f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized 2000 sequences with max length 16.\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(\n",
    "    dataset,\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "print(f\"Tokenized {inputs['input_ids'].shape[0]} sequences with max length {inputs['input_ids'].shape[1]}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc64664",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(\n",
    "        input_ids=inputs[\"input_ids\"],\n",
    "        attention_mask=inputs[\"attention_mask\"],\n",
    "        output_hidden_states=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83081090",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class LinearProbe(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(hidden_dim, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.linear(x)\n",
    "        probs = self.sigmoid(logits)\n",
    "        return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175fca65",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fraction = 0.2\n",
    "\n",
    "train_indices = np.arange(int(len(dataset)*(1 - test_fraction)))\n",
    "test_indices = np.arange(int(len(dataset)*(1 - test_fraction)), len(dataset))\n",
    "\n",
    "X_train, y_train = final_activations[train_indices, :], labels[train_indices]\n",
    "X_test, y_test = final_activations[test_indices, :], labels[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ae1aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "probe = LinearProbe(hidden_dim=final_activations.shape[1])\n",
    "optimizer = torch.optim.AdamW(probe.parameters(), lr=0.001)\n",
    "\n",
    "epochs = 500\n",
    "\n",
    "train_loss_history = []\n",
    "train_accuracy_history = []\n",
    "test_loss_history = []\n",
    "test_accuracy_history = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_prediction = probe.forward(X_train).squeeze()\n",
    "    test_prediction = probe.forward(X_test).squeeze()\n",
    "    train_loss = nn.BCELoss()(train_prediction, y_train.float())\n",
    "    test_loss = nn.BCELoss()(test_prediction, y_test.float())\n",
    "    train_loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    train_loss_history.append(train_loss.item())\n",
    "    train_predicted_classes = (train_prediction >= 0.5).long()\n",
    "    train_accuracy = (train_predicted_classes == y_train).float().mean().item()\n",
    "    train_accuracy_history.append(train_accuracy)\n",
    "\n",
    "    test_loss_history.append(test_loss.item())\n",
    "    test_predicted_classes = (test_prediction >= 0.5).long()\n",
    "    test_accuracy = (test_predicted_classes == y_test).float().mean().item()\n",
    "    test_accuracy_history.append(test_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "andrewstephenfletcher-github-io",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
