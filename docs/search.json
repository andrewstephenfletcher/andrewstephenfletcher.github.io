[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Andrew Stephen Fletcher",
    "section": "",
    "text": "I am a Data Scientist with an interest in AI Safety research. This website has a blog, where I plan to document my learning and a project space to chart progress on my MSc research project."
  },
  {
    "objectID": "about.html#bio",
    "href": "about.html#bio",
    "title": "Andrew Stephen Fletcher",
    "section": "",
    "text": "I am a Data Scientist with an interest in AI Safety research. This website has a blog, where I plan to document my learning and a project space to chart progress on my MSc research project."
  },
  {
    "objectID": "about.html#education",
    "href": "about.html#education",
    "title": "Andrew Stephen Fletcher",
    "section": "Education",
    "text": "Education\nUniversity of Oxford | Physics MPhys | 2019 - 2023\nUniversity of Exeter | Data Science MSc | 2023 - present"
  },
  {
    "objectID": "about.html#experience",
    "href": "about.html#experience",
    "title": "Andrew Stephen Fletcher",
    "section": "Experience",
    "text": "Experience\nBBC Studios | Data Science | Researching machine learning methods for predicting TV viewing | 2023 - present\nBlueDot | Technical AI Safety Course Course introducing ideas in technical AI safety | 2025"
  },
  {
    "objectID": "blog/posts/test-post/index.html",
    "href": "blog/posts/test-post/index.html",
    "title": "First Post: Test Post",
    "section": "",
    "text": "This is a test post for my blog!"
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Projects",
    "section": "",
    "text": "Order By\n      Default\n      \n      \n      \n        Title\n      \n      \n        Team\n      \n      \n        Funder\n      \n      \n        Description\n      \n      \n        Start\n      \n      \n        End\n      \n      \n        Funding\n      \n    \n  \n    \n      \n      \n    \n\n\n\n\n\n\n \n\n\n\nTitle\n\n\n\nTeam\n\n\n\nFunder\n\n\n\nDescription\n\n\n\nFunding\n\n\n\nStart\n\n\n\nEnd\n\n\n\n\n\n\n\n\n\n\n\nExploring \n\n\nAcademic Website\n\n\nFunder\n\n\nThe goal of this project is to investigate .\n\n\n$0\n\n\n2024\n\n\n2025\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "projects/index.html",
    "href": "projects/index.html",
    "title": "AI Safety Projects",
    "section": "",
    "text": "Interactive experiments and code visualizations.\n\n\n\n\n\n\n\n\n\n\n\n\nReward Misspecification Plot\n\n\nA visualization of agent behavior under faulty reward functions.\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/news-title/index.html",
    "href": "posts/news-title/index.html",
    "title": "News item",
    "section": "",
    "text": "About the news"
  },
  {
    "objectID": "posts/news-title/index.html#summary",
    "href": "posts/news-title/index.html#summary",
    "title": "News item",
    "section": "",
    "text": "About the news"
  },
  {
    "objectID": "posts/paper-title/index.html#abstract",
    "href": "posts/paper-title/index.html#abstract",
    "title": "Can quantum-mechanical description of physical reality be considered complete?",
    "section": "Abstract",
    "text": "Abstract\nIn a complete theory there is an element corresponding to each element of reality. A sufficient condition for the reality of a physical quantity is the possibility of predicting it with certainty, without disturbing the system. In quantum mechanics in the case of two physical quantities described by non-commuting operators, the knowledge of one precludes the knowledge of the other. Then either (1) the description of reality given by the wave function in quantum mechanics is not complete or (2) these two quantities cannot have simultaneous reality. Consideration of the problem of making predictions concerning a system on the basis of measurements made on another system that had previously interacted with it leads to the result that if (1) is false then (2) is also false. One is thus led to conclude that the description of reality as given by a wave function is not complete."
  },
  {
    "objectID": "posts/paper-title/index.html#links",
    "href": "posts/paper-title/index.html#links",
    "title": "Can quantum-mechanical description of physical reality be considered complete?",
    "section": "Links",
    "text": "Links\nPublished paper"
  },
  {
    "objectID": "projects/safety-viz.html",
    "href": "projects/safety-viz.html",
    "title": "Reward Misspecification Plot",
    "section": "",
    "text": "Here is a quick Python test to verify my interactive elements:\nimport matplotlib.pyplot as plt import numpy as np\nx = np.linspace(0, 10, 100) y = np.exp(x / 3) # Exponential ‘risk’ plot\nplt.plot(x, y, color=‘red’) plt.title(“Agent Risk Profile”) plt.show()"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Andrew Stephen Fletcher",
    "section": "",
    "text": "I am a Data Scientist with an interest in AI Safety research. I am keen to learn more about many areas but have started diving into Latent Space Monitoring. This website has a blog, mainly focused on explaining AI safety techniques as I learn them."
  },
  {
    "objectID": "index.html#bio",
    "href": "index.html#bio",
    "title": "Andrew Stephen Fletcher",
    "section": "",
    "text": "I am a Data Scientist with an interest in AI Safety research. I am keen to learn more about many areas but have started diving into Latent Space Monitoring. This website has a blog, mainly focused on explaining AI safety techniques as I learn them."
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Andrew Stephen Fletcher",
    "section": "Education",
    "text": "Education\nUniversity of Exeter | Data Science MSc\nDeep learning and PyTorch | 2023 - present\nUniversity of Oxford | Physics MPhys\nFocus on Astrophysics | 2019 - 2023"
  },
  {
    "objectID": "index.html#experience",
    "href": "index.html#experience",
    "title": "Andrew Stephen Fletcher",
    "section": "Experience",
    "text": "Experience\nBBC Studios | Data Science\nML research predicting TV viewing | 2023 - present\nBlueDot | Technical AI Safety Course\nCourse introducing ideas in technical AI safety | 2025"
  },
  {
    "objectID": "blog/index.html",
    "href": "blog/index.html",
    "title": "Blog",
    "section": "",
    "text": "Notes and deep-dives into AI alignment research.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFirst Post: Test Post\n\n\n\nresearch\n\nintro\n\n\n\n\n\n\n\n\n\nJan 21, 2026\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog/posts/test-post/index.html#testing-interactive-plots",
    "href": "blog/posts/test-post/index.html#testing-interactive-plots",
    "title": "First Post: Test Post",
    "section": "Testing Interactive Plots",
    "text": "Testing Interactive Plots\nTo verify my AI Safety visualization pipeline, here is a simple sine wave generated using Matplotlib.\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Data for the sine wave\nx = np.linspace(0, 2 * np.pi, 100)\ny = np.sin(x)\n\n# Create the plot\nplt.figure(figsize=(8, 4))\nplt.plot(x, y, label='Sine Wave', color='blue', linewidth=2)\nplt.title(\"Baseline Visualization Test\")\nplt.xlabel(\"Radians\")\nplt.ylabel(\"Amplitude\")\nplt.grid(True, linestyle='--', alpha=0.7)\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nThis basic plotting now we try an interactive plot.\n\nimport plotly.graph_objects as go\nimport numpy as np\n\n# Create the signal data\nx = np.linspace(0, 10, 500)\nfreqs = np.arange(1, 6, 1)\n\nfig = go.Figure()\n\n# Add a trace for each frequency (hidden by default except the first)\nfor f in freqs:\n    fig.add_trace(\n        go.Scatter(\n            visible=False,\n            line=dict(color=\"#00CED1\", width=3),\n            name=f\"f = {f}\",\n            x=x,\n            y=np.sin(f * x)\n        )\n    )\n\n# Make the first trace visible\nfig.data[0].visible = True\n\n# Create the slider steps\nsteps = []\nfor i in range(len(fig.data)):\n    step = dict(\n        method=\"update\",\n        args=[{\"visible\": [False] * len(fig.data)},\n              {\"title\": f\"Sine Wave Frequency: {i+1}Hz\"}],\n        label=str(i+1)\n    )\n    step[\"args\"][0][\"visible\"][i] = True\n    steps.append(step)\n\n# Add the slider to the layout\nsliders = [dict(\n    active=0,\n    currentvalue={\"prefix\": \"Frequency: \"},\n    pad={\"t\": 50},\n    steps=steps\n)]\n\nfig.update_layout(sliders=sliders, title=\"Interactive Frequency Test\")\nfig.show()\n\n                            \n                                            \n\n\nNow a correlation matrix plot.\n\nimport plotly.express as px\nimport numpy as np\nimport pandas as pd\n\n# Generate dummy AI Safety metrics data\ndata = {\n    'Reward': [0.9, 0.8, 0.2, 0.4, 0.1],\n    'Safety_Buffer': [0.1, 0.2, 0.8, 0.6, 0.9],\n    'Compute_Used': [1.0, 0.8, 0.5, 0.3, 0.2],\n    'Alignment_Score': [0.8, 0.7, 0.3, 0.5, 0.2]\n}\ndf = pd.DataFrame(data)\ncorr = df.corr()\n\n# Create the heatmap\nfig = px.imshow(\n    corr,\n    text_auto=\".2f\", # Shows the correlation values inside the cells\n    aspect=\"auto\",\n    color_continuous_scale='RdBu_r', # Red/Blue diverging scale\n    zmin=-1, zmax=1,                 # Standard correlation limits\n    title=\"Feature Correlation Matrix: Safety Metrics\"\n)\n\nfig.update_layout(\n    plot_bgcolor='white',\n    font=dict(family=\"Inter, sans-serif\", size=12) # Matches common Quarto themes\n)\n\nfig.show()"
  },
  {
    "objectID": "notebooks/Branching model tutorial.html",
    "href": "notebooks/Branching model tutorial.html",
    "title": "Recreating branching model animations",
    "section": "",
    "text": "Artem Kirsanov, August 2023\n\n\nCode\nimport numpy as np\nfrom copy import deepcopy\nimport itertools\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom numpy import radians as rad\nfrom matplotlib.animation import FuncAnimation\nfrom scipy.ndimage import convolve,convolve1d\nimport cmasher\nimport seaborn as sns\n\n\n\nMatplotlib\n\n\nCode\nNUM_LAYERS = 20\nNEURONS_PER_LAYER = 10\n\n\n\n\nCode\ndef network_init():\n    return np.zeros((NUM_LAYERS, NEURONS_PER_LAYER),dtype=bool)\n\n\ndef network_advance(old_network, sigma,spont_prob):\n    '''Advance one time step'''\n    network = deepcopy(old_network)\n    spont = np.random.rand(*network.shape)\n    network[spont&lt;spont_prob] = 1 # Random spontaneous activity\n    for layer_num in range(NUM_LAYERS-1, 0, -1):\n        # Randomly propagate, starting from the last layer\n        propagation_mask = np.random.rand(NEURONS_PER_LAYER) &lt; sigma*np.sum(network[layer_num-1,:])/NEURONS_PER_LAYER\n        network[layer_num] = propagation_mask\n        network[layer_num-1] = np.zeros(NEURONS_PER_LAYER)\n    return network\n\n\ndef run_simulation(network, n_steps, sigma=1, spont_prob=0.01):\n    '''Run simulation with stochastic activity for n_steps'''\n    network_states = np.zeros((n_steps, NUM_LAYERS, NEURONS_PER_LAYER))\n    network_states[0,:,:] = network\n\n    for step in range(1,n_steps):\n        network_states[step, :,:] = network_advance(network_states[step-1, :,:], sigma,spont_prob)\n    return network_states\n\n\n\n\nCode\nnetwork = network_init()\nevolution = run_simulation(network, 50, sigma=1, spont_prob=0.01)\n\n\n\n\nCode\nfig, ax = plt.subplots(1,1,figsize=(10,5),dpi=200)\nax.axis(False)\nfig.set_facecolor(\"black\")\nax.set_facecolor(\"black\")\n\ncmesh = ax.pcolormesh(evolution[0,:,:].T, edgecolors='k', vmin=0, vmax=1,linewidth=2, cmap=plt.cm.coolwarm)\n\ndef anim_function(frame_num):\n    cmesh.set_array(evolution[frame_num,:,:].T)\n    return cmesh,\n\nanim = FuncAnimation(fig, anim_function, frames=np.arange(evolution.shape[0]), interval=30)\nanim.save(\"Network evolution raw fast.mp4\")\n\n\n\n\n\n\n\n\n\n\n\nCode\n# --- Running the model\nnetwork = network_init()\nevolution = run_simulation(network, 500, sigma=1, spont_prob=0.01)\n\n# --- Smoothing activity\ndef smooth_activity(network_states, time_stretch=3):\n    '''\n        Smooth the activity in time for a more eye-pleasant animation\n    '''\n    def get_symmetric_kernel(slope=-20, npoints=100):\n        t = np.linspace(0,1,npoints)\n        kernel = np.zeros_like(t)\n        t_mask = t&gt;0.5\n        kernel[t_mask]=np.exp(slope*t[t_mask])\n        kernel[(t&lt;=0.5)]=np.exp(slope*t[t_mask])[::-1]\n        return kernel/kernel[t_mask][0]\n\n    kernel = get_symmetric_kernel(-60)\n    smoothed_activity = np.zeros((network_states.shape[0]*time_stretch, network_states.shape[1], network_states.shape[2]))\n    smoothed_activity[::time_stretch, :, :] = network_states\n    smoothed_activity = convolve1d(smoothed_activity, kernel, axis=0,mode=\"constant\",origin=0)\n    return smoothed_activity\n\n\n\n\nCode\n# --- Animation\nsmoothed_evolution = smooth_activity(evolution)\nfig, ax = plt.subplots(1,1,figsize=(10,5),dpi=200)\nax.axis(False)\nfig.set_facecolor(\"black\")\nax.set_facecolor(\"black\")\n\ncmap = cmasher.get_sub_cmap(sns.color_palette(\"mako\",as_cmap=True),0.2,1)\ncmesh = ax.pcolormesh(smoothed_evolution[0,:,:].T, edgecolors='k', vmin=0, vmax=1,linewidth=2, cmap=cmap)\n\ndef anim_function(frame_num):\n    cmesh.set_array(smoothed_evolution[frame_num,:,:].T)\n    return cmesh,\n\nanim = FuncAnimation(fig, anim_function, frames=np.arange(smoothed_evolution.shape[0]), interval=30)\nanim.save(\"Network evolution smoothed.mp4\")\n\n\n[01/27/26 11:10:47] INFO     Animation.save using &lt;class 'matplotlib.animation.FFMpegWriter'&gt;     animation.py:1076\n\n\n\n                    INFO     MovieWriter._run: running command: ffmpeg -f rawvideo -vcodec         animation.py:319\n                             rawvideo -s 2000x1000 -pix_fmt rgba -framerate 33.333333333333336                     \n                             -loglevel error -i pipe: -vcodec h264 -pix_fmt yuv420p -y 'Network                    \n                             evolution smoothed.mp4'                                                               \n\n\n\n\n\n\n\n\n\n\n\n\nManim\n\n\nCode\nNUM_LAYERS = 10\nNEURONS_PER_LAYER = 10\nNUM_FRAMES=2000\n\n# --- Simulation\nnetwork = network_init()\nnetwork_states = run_simulation(network, NUM_FRAMES, sigma=1,spont_prob=0.01)\nsmoothed_states = smooth_activity(network_states)\n\n\n\n\nCode\ndef multilayered_graph(subset_sizes, edge_prob=0.35):\n    ''' Generate a networkx multilayered graph with specied layer sizes '''\n    extents = nx.utils.pairwise(itertools.accumulate([0] + subset_sizes))\n    layers = [range(start, end) for start, end in extents]\n    G = nx.Graph()\n    for (i, layer) in enumerate(layers):\n        G.add_nodes_from(layer, layer=i)\n    for layer1, layer2 in nx.utils.pairwise(layers):\n        all_edges = list(itertools.product(layer1, layer2))\n        selected_edges = np.random.choice(range(len(all_edges)),  size=int(len(all_edges)*edge_prob), replace=False)\n        for k in selected_edges:\n            G.add_edge(*all_edges[k])\n    return G\n\n\n\n\nCode\nfrom manim import *\nimport networkx as nx\nfrom scipy.interpolate import interp1d\nimport itertools\n\n\n/Users/fletcaw1/Documents/Personal/personal-repos/andrewstephenfletcher.github.io/.venv/lib/python3.12/site-packages/pydub/utils.py:300: SyntaxWarning: invalid escape sequence '\\('\n  m = re.match('([su]([0-9]{1,2})p?) \\(([0-9]{1,2}) bit\\)$', token)\n/Users/fletcaw1/Documents/Personal/personal-repos/andrewstephenfletcher.github.io/.venv/lib/python3.12/site-packages/pydub/utils.py:301: SyntaxWarning: invalid escape sequence '\\('\n  m2 = re.match('([su]([0-9]{1,2})p?)( \\(default\\))?$', token)\n/Users/fletcaw1/Documents/Personal/personal-repos/andrewstephenfletcher.github.io/.venv/lib/python3.12/site-packages/pydub/utils.py:310: SyntaxWarning: invalid escape sequence '\\('\n  elif re.match('(flt)p?( \\(default\\))?$', token):\n/Users/fletcaw1/Documents/Personal/personal-repos/andrewstephenfletcher.github.io/.venv/lib/python3.12/site-packages/pydub/utils.py:314: SyntaxWarning: invalid escape sequence '\\('\n  elif re.match('(dbl)p?( \\(default\\))?$', token):\n\n\n\n\nCode\n# --- Animation with Manim\nclass BranchingModelRearranging(Scene):\n    def construct(self):\n\n        # Set up coordinate systems\n        shuffled_ax = Axes(x_range=(0,NUM_LAYERS), y_range=(0,NEURONS_PER_LAYER),x_length=7, y_length=7)\n        layers_ax = Axes(x_range=(0,NUM_LAYERS), y_range=(0,NEURONS_PER_LAYER),x_length=13, y_length=7)\n\n        # --- Mapping\n        mapping = np.array(list(itertools.product(range(shuffled_ax.x_range[1]), range(shuffled_ax.y_range[1]))), dtype=object)\n        layout_layered = {k: layers_ax.c2p(*mapping[k]) for k in range(NUM_LAYERS*NEURONS_PER_LAYER)}\n        np.random.shuffle(mapping)\n        layout_shuffle = {k: shuffled_ax.c2p(*mapping[k]) for k in range(NUM_LAYERS*NEURONS_PER_LAYER)}\n\n        # Construct a graph object\n        G = multilayered_graph(([NEURONS_PER_LAYER]*NUM_LAYERS))\n        graph = Graph.from_networkx(G,layout=layout_shuffle,vertex_config={'radius': 0.2},\n                                    edge_config={\"stroke_width\":0.5, \"stroke_color\":GRAY})\n\n        # Interpolation function to animate the color of the nodes according to simulation data\n        value_interp_function = interp1d(np.arange(smoothed_states.shape[0]),\n                                         smoothed_states.reshape(smoothed_states.shape[0], NUM_LAYERS*NEURONS_PER_LAYER), axis=0)\n\n        cmap = cmasher.get_sub_cmap(sns.color_palette(\"mako\",as_cmap=True),0.2,1)\n\n\n        def update_node_colors(graph):\n            for k in range(len(G.nodes)):\n                color =  cmap(value_interp_function(time_tracker.get_value())[k])\n                graph[k].set_color(rgba_to_color(color))\n\n        time_tracker = ValueTracker() # Progressing through simulation data\n        graph.add_updater(update_node_colors)\n        self.add(graph)\n\n        # --- Animating (make sure that there is enough frames in the simulation data)\n        FPS = 30\n        PLAY_TIME_BEFORE_REARRANGING = 20\n        PLAY_TIME_AFTER_REARRANGING = 5\n        REARRANGING_TIME = 2\n\n        def get_shuffle2layered_anims():\n            return [graph[k].animate.move_to(layout_layered[k]) for k in range(len(G.nodes))]\n\n        def animate_network(playing_time):\n            self.play(time_tracker.animate.increment_value(int(playing_time*FPS)), run_time=playing_time, rate_func=linear)\n\n        animate_network(PLAY_TIME_BEFORE_REARRANGING)\n\n\n        self.play(*(get_shuffle2layered_anims() +\n                    [time_tracker.animate.increment_value(int(REARRANGING_TIME*FPS))]),\n                    run_time=REARRANGING_TIME, rate_func=linear)\n\n        animate_network(PLAY_TIME_AFTER_REARRANGING)\n        self.wait()"
  },
  {
    "objectID": "notebooks/residual_stream_animation.html",
    "href": "notebooks/residual_stream_animation.html",
    "title": "Andrew Stephen Fletcher",
    "section": "",
    "text": "Code\nimport numpy as np\n\n\n\n\nCode\nd_model = 768\nn_layers = 12\n\nresidual_stream = np.random.randn(n_layers, d_model)\n\nresidual_stream.shape\n\n\n(12, 768)\n\n\nLet’s use Einops to rearrange this into a nice array to visualize.\n\n\nCode\nfrom einops import rearrange, reduce, repeat\n\nresidual_stream = rearrange(residual_stream, \"layer (row col) -&gt; layer row col\", row=16)\n\nresidual_stream.shape\n\n\n(12, 16, 48)\n\n\nNow we do the simplest plot of such a tensor.\n\n\nCode\nimport matplotlib.pyplot as plt\n\nplt.imshow(residual_stream[0], cmap='viridis')\nplt.title(\"Residual Stream at Layer 0\")\nplt.show()\n\n\n\n\n\n\n\n\n\nWe want to make this much prettier for the blog.\n\n\nCode\nfig, ax = plt.subplots(1,1, figsize=(15,5))\nax.axis(False)\nfig.set_facecolor('black')\nax.set_facecolor('black')\n\ncmesh = ax.pcolormesh(residual_stream[0], edgecolors='k', cmap='viridis', vmin=-3, vmax=3)\n\n\n\n\n\n\n\n\n\nNow we can think about animating this.\n\n\nCode\nfrom matplotlib.animation import FuncAnimation\n\ndef anim_function(frame_num):\n    cmesh.set_array(residual_stream[frame_num,:,:])\n    return cmesh,\n\nanim = FuncAnimation(fig, anim_function, frames=np.arange(residual_stream.shape[0]), interval=30)\n\nfrom IPython.display import HTML\nHTML(anim.to_jshtml())\n\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\nNow lets look to do something with actual model activations!\n\n\nCode\nfrom huggingface_hub import login\nlogin()\n\n\n\n\nCode\nimport torch\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\n\nmodel_name = \"gpt2\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForCausalLM.from_pretrained(model_name)\ntokenizer.pad_token = tokenizer.eos_token\n\n\n\n\n\nGPT2LMHeadModel LOAD REPORT from: gpt2\nKey                  | Status     |  | \n---------------------+------------+--+-\nh.{0...11}.attn.bias | UNEXPECTED |  | \n\nNotes:\n- UNEXPECTED    :can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n\n\n\n\nCode\ninputs = tokenizer(\n    \"The capital of France is \",\n    padding=True,\n    truncation=True,\n    return_tensors=\"pt\"\n)\n\nprint(f\"Tokenized {inputs['input_ids'].shape[0]} sequences with max length {inputs['input_ids'].shape[1]}.\")\n\n\nTokenized 1 sequences with max length 6.\n\n\n\n\nCode\nwith torch.no_grad():\n    outputs = model(\n        input_ids=inputs[\"input_ids\"],\n        attention_mask=inputs[\"attention_mask\"],\n        output_hidden_states=True,\n    )\n\n\n\n\nCode\ntype(outputs.hidden_states)\n\n\ntuple\n\n\n\n\nCode\noutputs.hidden_states[12][0, -1, :]\n\n\ntensor([ 2.1710e-01, -7.7295e-01,  1.1417e+00, -8.3475e-01,  2.2499e-01,\n         1.3656e-01,  2.0857e+00,  1.1435e-01,  3.4787e-02,  2.7007e-03,\n        -6.6976e-01, -7.1862e-01, -9.2031e-01,  4.4544e-01,  1.2125e+00,\n        -5.5891e-01, -1.0116e+00, -3.8677e-03,  4.2669e-01,  4.6396e-02,\n         9.8095e-01,  6.2097e-02, -3.3693e-01, -1.6890e-01, -8.7173e-01,\n        -6.8546e-02,  1.6516e+00, -1.3884e+00, -2.9503e-01, -1.9288e-01,\n        -1.6748e+00,  1.1511e+00,  3.6825e-01, -3.7181e-01, -9.5687e-01,\n        -2.4434e-01,  8.3507e+01,  8.0384e-01, -1.0355e+00,  4.9273e-01,\n         6.7548e-01, -1.1068e+00,  1.6872e-01, -3.0498e-01,  4.2572e-01,\n         6.5657e-01, -1.0069e+00,  2.0134e-03, -4.8117e-01,  1.0097e+00,\n         3.4534e-01, -3.1412e-01,  4.6457e-01,  4.8710e-01, -4.6544e-01,\n         2.2776e+00,  7.9419e-01, -3.0419e-01, -3.9436e-01, -4.4826e-01,\n        -7.9496e-01,  4.8636e-01, -1.4069e+00, -7.9174e-02, -1.1013e+00,\n        -4.5765e-01,  2.5305e-01, -1.0385e+00, -1.3553e+00,  1.1607e-01,\n        -6.5547e-01, -5.2312e-01, -3.6168e-01, -3.9353e-01, -5.8317e-01,\n        -6.7036e-01, -1.2292e+00, -5.2466e+00, -8.1132e-01, -4.7962e-02,\n        -3.1652e-01, -5.5677e-01,  9.7363e-01, -1.9221e+00,  1.1459e-01,\n         7.8668e-01,  2.8420e+00, -1.0191e+00,  5.7042e-01, -5.0858e-01,\n         6.4895e-01,  6.2247e-02, -9.4832e-01, -1.3130e+00,  4.1395e-01,\n         2.4583e-01, -9.4302e-02, -2.0484e-01,  4.1979e-01,  1.3451e+00,\n        -1.1539e+00, -2.8649e-02, -3.4690e-01,  8.7150e-01, -2.4732e-02,\n         1.4023e-02, -1.8437e-01,  7.6167e+00, -2.3778e-01, -1.2093e+00,\n        -4.8684e-01, -8.5886e-01, -8.6230e-01,  1.3440e+00, -6.5799e-01,\n         3.8584e-01,  1.5129e+00, -1.0419e+00,  7.1840e-01,  6.5000e-02,\n         8.9308e-01,  1.5453e+00, -1.6132e-01,  7.6579e-01, -5.2532e-01,\n         5.9511e-01, -2.0430e-02, -6.1319e-01, -7.0808e-01, -4.2580e-02,\n        -4.5041e-01, -1.1142e+00,  7.0570e-02,  5.7309e-01, -2.8080e-03,\n         1.6073e+00, -8.4978e-01,  7.4317e-01,  5.4909e-01, -9.5504e-02,\n        -1.4985e+00, -9.5762e-02,  6.7423e-01, -2.5118e-02,  2.3879e-01,\n        -7.8086e-02, -9.9612e-02, -9.1868e-01, -5.7182e-01,  1.2112e+00,\n         5.3186e-01,  9.7128e-01,  3.0943e-02,  1.6023e-01,  1.1300e+00,\n         1.3110e-01, -8.3382e-02, -7.7245e-01,  8.8341e-02, -7.5046e-01,\n        -3.1946e-01, -1.3778e-01,  8.3454e-01, -2.5601e-01,  1.1346e+00,\n        -2.6478e-01,  1.5536e-01,  1.7761e+00,  4.3640e-02, -3.6560e-01,\n         3.8196e-01, -4.6101e-01, -5.9228e-01,  6.7572e-01,  7.9012e-01,\n         7.0019e-01,  3.0845e-01, -1.6915e-01, -1.9187e-01, -6.9731e-01,\n         4.2516e-01,  8.4774e-01, -8.8573e-01,  2.1263e-01,  1.3646e-01,\n        -1.1130e+00,  7.1921e-01,  7.3364e-01,  4.9774e-01, -3.8298e-01,\n        -5.1544e-01, -4.3921e-01, -2.6954e-01,  7.6078e-01,  3.3569e-01,\n        -1.8321e+00,  6.3892e-01,  3.3424e-01, -1.1647e-01,  1.1811e+00,\n        -5.7590e-01,  5.4765e-01, -1.1107e+00,  1.8905e-01, -1.2921e-01,\n        -2.4979e-01,  5.8968e-01, -3.9001e-01, -1.0312e+00, -1.0040e+00,\n         4.6013e-01, -5.7743e-01, -4.1954e-01,  1.2826e-01, -5.2482e-01,\n        -4.6590e-01,  3.2724e-01, -1.0745e+00, -1.2736e+00, -4.1784e-02,\n         7.3616e-01,  8.9963e-01, -7.9668e-01,  1.7886e-01,  1.1084e+00,\n         1.4245e-01,  5.8861e-01,  1.7566e-01,  2.7915e-01,  2.0262e+00,\n         4.6237e-01,  2.4559e-01,  1.1593e+00, -2.9097e-01, -7.2626e-01,\n        -2.9313e-01,  4.0753e-01, -6.3202e-02, -8.8094e-02, -7.2448e-01,\n         3.6668e-01, -1.3999e-02,  1.8221e-01,  2.1109e-01,  4.0177e-01,\n         4.6528e-01,  7.9413e-02, -7.0166e-01,  1.0111e+00, -5.6132e-01,\n        -2.7929e+00,  6.1686e-01,  6.5091e-01, -4.0908e-01,  7.7313e-01,\n        -2.7332e-01,  3.0686e-01, -4.2479e-01, -2.7674e-01,  3.4369e-01,\n        -2.2121e-01, -2.0228e-01,  1.1675e-02, -5.7812e-01,  7.9043e-02,\n        -1.0334e-01, -9.9720e-01, -9.6778e-01,  3.8705e-01, -5.6668e-01,\n         1.9873e-01, -2.9083e-01,  1.1242e+00,  4.2393e-02,  1.4896e+00,\n        -6.0494e-01, -6.2929e-02,  1.0571e-01, -3.3332e-01, -7.6395e-01,\n         8.8787e-01, -7.6457e-01,  1.6207e-01, -3.7911e-01,  3.4710e-01,\n         4.5784e-01,  2.5686e-01, -1.0352e-01, -2.7344e-01, -3.8722e-01,\n        -3.8882e-02, -1.0850e+00,  3.7326e-01,  1.3742e+00, -1.1163e+00,\n        -2.2921e-01, -5.2011e-02, -2.7574e-01, -6.8880e-01, -1.2636e+00,\n        -2.1455e+00,  3.0525e-01,  1.8934e-03,  2.2449e-01,  1.0341e+00,\n         9.4804e-03, -7.0624e-01,  3.1657e-01,  8.5579e-01,  6.4260e-01,\n         7.5086e-01,  1.3329e+00,  7.2702e-01, -1.4670e+00, -1.5507e+00,\n        -3.0910e-01,  8.9624e-01,  7.7060e-01, -2.6838e-01,  3.4735e-01,\n        -9.7500e-01, -3.2034e-01,  2.3541e-01, -1.3876e+00,  2.8181e-01,\n        -1.8600e-02, -7.1686e-01,  3.2502e-01,  7.3856e-01,  2.5005e-01,\n         2.3833e-01, -1.3180e+00,  1.0017e+00,  1.0708e-02, -3.3465e-01,\n         6.8047e-01,  7.5732e-01,  2.8348e-01, -6.2277e-01, -7.0794e-01,\n         4.0756e-02,  5.9620e-02, -7.8866e-01, -9.0276e-01, -1.5886e-01,\n         1.1635e+00,  2.7243e-01,  4.6438e-01,  2.4842e-01,  1.7146e-01,\n        -2.7772e-01,  1.2380e+00,  7.2914e-01,  3.0305e-01,  4.3475e-01,\n        -3.9751e-01, -1.4432e+00,  3.6403e-02,  6.3998e-01, -1.0309e-01,\n         8.3384e-01,  3.9767e+00,  3.4758e-02, -6.1287e-01,  1.1300e+00,\n         3.1228e-01,  2.4406e-01, -1.2377e-01, -1.3691e-01, -1.1380e-01,\n         5.7062e-01, -6.0428e-01,  6.4441e-01, -1.1809e+00, -9.3918e+00,\n        -8.2759e-02,  1.8465e-01,  9.8914e-01,  1.1676e-01, -4.7337e-01,\n         7.3695e-01,  1.4989e-01, -4.7603e-01,  5.7831e-01,  4.9050e-01,\n         4.8735e-01, -8.6071e-01,  3.3436e-01, -1.4266e+00,  1.9742e+00,\n         4.8320e-01, -7.4013e-02, -4.2630e-01, -4.1942e-01,  3.6049e-01,\n        -2.4850e-01, -2.1843e+00, -3.5065e-01, -1.3229e+00, -9.8485e-01,\n        -8.5891e-03,  1.1276e+00, -3.4453e-01,  3.6816e-01,  6.2270e-01,\n         6.4265e-01, -1.0245e+00, -1.1595e-01,  1.3920e+00, -5.2577e-01,\n         8.3284e-01,  1.8259e-01,  2.9163e-01, -1.2783e+00, -6.5119e-01,\n         3.8518e-01,  1.9796e+00, -9.3330e-02, -1.0774e+00, -4.2899e-01,\n        -1.1500e+00, -8.5962e-01, -3.1886e-01, -2.0775e-01,  1.7833e-01,\n        -2.1804e-01, -2.4947e-01, -6.2149e-01, -6.2778e-01,  3.3302e-01,\n         7.6082e+01, -9.5729e-01, -7.4412e-01, -3.0139e-01, -3.0915e-01,\n         3.4585e-01,  5.7178e-01,  9.1261e-01,  4.6012e-01,  3.3710e-02,\n         7.6602e-01, -2.9276e-01,  7.8121e+00, -3.7865e-01,  8.8373e-02,\n        -6.3207e-01,  3.9716e-01,  1.0505e+00, -8.4078e-02, -2.0532e-01,\n         1.5611e-02,  1.6427e-01, -9.5319e-02, -1.7369e+00,  2.1381e-01,\n         1.6194e+00, -6.3267e-01, -3.8917e-02, -1.4348e+00, -1.7357e+00,\n         6.6774e-01, -5.4839e-01, -5.5232e-01, -9.9893e-01,  1.0580e+00,\n        -1.0668e+00, -1.8787e-01, -5.7900e-01,  1.7256e+00,  1.6962e-01,\n         2.3930e-01, -3.7141e-01, -6.5737e-02,  3.3034e-01, -4.9337e-01,\n        -4.4169e-01, -2.5936e-01, -6.5827e-01,  3.9347e-01, -7.0036e+00,\n        -8.8276e-01,  1.1817e+00,  4.5564e-01, -6.0512e-01,  1.0501e+00,\n        -1.6834e-01, -1.6229e-01,  5.8124e-03, -4.2478e-01,  6.7488e-02,\n        -5.5760e-02,  1.0489e-01,  4.6643e-01,  3.9835e-01,  2.4331e-02,\n        -5.6885e-01,  1.6761e+02, -1.0206e+00, -1.3635e+00,  5.2503e-01,\n        -1.2565e-01, -2.2732e-01, -6.1060e-02, -1.8880e+00, -6.9495e-01,\n        -1.5009e-01, -7.5009e-01,  1.0522e+00, -1.8798e-01, -2.8763e-01,\n         4.2106e-01, -9.0198e-01, -1.1934e+00, -2.1196e-01, -4.9072e-01,\n        -9.7793e-03, -2.0616e-01,  6.0449e-01,  9.6383e-02,  3.9358e-02,\n        -7.0781e-01,  3.1003e-01, -5.5014e-01, -1.1874e-01, -9.3202e-01,\n         7.9600e-01,  3.5735e-01,  7.7984e-01, -3.5457e-01, -3.5996e-01,\n        -6.0434e-01,  2.2980e-01,  8.1210e-01, -4.8096e-01, -3.5203e-01,\n        -2.5323e-01,  6.1843e-01, -4.0568e-01, -1.4090e+00,  6.4991e-01,\n        -5.8201e-02,  3.7496e-01,  5.2005e-01,  3.6404e+00, -2.4760e-01,\n         1.2322e+00, -4.7927e-01, -4.4899e-01, -6.9502e-01,  9.2428e-01,\n         1.0538e+00,  1.6555e+00,  6.0869e-02,  4.7457e-01, -4.0441e+00,\n        -9.7015e-02,  4.2082e-01,  1.2562e+00, -7.7863e-01, -9.9768e-01,\n         2.2036e-01,  5.4304e-01,  3.4944e-01, -8.6384e-01,  2.6555e-01,\n        -2.4269e-01, -9.2181e-01, -9.2686e-01, -1.0830e+00,  2.4752e-01,\n         2.5278e-01, -2.0007e-01, -7.4657e-01, -9.1094e-01, -1.4554e+00,\n         1.4533e+00, -1.0371e+00,  4.4040e-01, -6.0298e-01,  2.0082e-02,\n         1.3035e-01,  2.7692e-01,  2.7869e-01,  1.3556e+00, -9.9423e-01,\n         1.2892e-01, -4.4968e-04, -1.0127e+00, -2.3068e-01,  1.9994e-01,\n        -6.7468e-01,  2.8012e-01, -5.9776e-01,  1.1516e+00, -2.8708e-01,\n        -4.0061e-01, -4.0816e-01,  1.4959e-01, -1.1326e-01, -3.5905e-01,\n        -7.0118e-01, -3.0393e-01,  1.8876e-01,  1.2278e+00, -5.5151e-01,\n        -1.0801e-01,  5.0410e-01,  1.9230e-01, -2.0004e-02,  1.7328e+00,\n         2.8549e-01,  5.6595e-01,  6.0942e-01,  1.1001e-01,  3.8970e-02,\n         9.3271e-01,  4.9661e-01, -1.4651e-01, -2.8887e-01, -8.5027e-02,\n        -1.2363e-01,  1.8735e+00,  1.4853e+00, -5.0505e+00, -6.6130e-02,\n         1.4936e+00,  3.7260e-01, -1.2740e+00, -5.0597e-01, -2.4129e-01,\n        -3.1131e-01, -6.8725e-02, -5.6239e-01,  8.9986e-01, -2.8544e-01,\n         1.0289e+00, -1.4950e-01,  7.6990e-01,  5.4520e-01,  7.1475e-01,\n        -1.1464e+00, -4.4244e-01,  7.4997e-01, -5.1890e-01, -4.6093e-01,\n        -7.1809e-01,  3.0428e-01,  1.3663e+00, -6.9241e-01, -2.5010e+00,\n         4.3145e-03,  3.4858e-01, -2.4944e-02, -1.3317e-01, -1.4323e-01,\n        -3.1365e-01, -2.3933e-01, -5.5166e-01, -4.3432e-01,  5.7165e-01,\n        -1.3776e-01,  5.5937e-01,  9.7620e-01, -1.0090e-01,  7.2589e-01,\n         3.8378e-01, -1.1367e-01, -2.1732e-01,  2.0220e-01, -1.6036e-01,\n        -9.3897e-01,  6.4239e-01,  6.0103e-01, -1.7983e-01, -1.0958e-01,\n         1.2053e+00, -3.3088e-01, -5.0474e-01, -9.0186e-01,  5.6167e-01,\n        -2.8098e-01,  7.1406e-01, -1.5541e-01,  3.9947e-01, -2.0957e-01,\n        -4.2226e-01, -2.2324e-01,  2.7149e-01,  1.3881e+00,  3.2717e-01,\n         1.0344e+00, -6.1723e-01, -1.0749e+00, -5.8085e-01, -2.8638e-01,\n         3.7234e-01,  1.2916e-01, -8.3189e-01,  7.9083e-01, -9.9141e-01,\n         4.6588e-01,  5.2980e-01,  1.8897e-01, -1.6154e+01, -1.5997e+00,\n        -1.1243e-01,  1.4577e+00,  5.7553e-01, -3.2472e-01, -3.5956e-01,\n        -5.5007e-01, -8.3341e-01,  4.6754e-01,  1.0044e+00, -3.4620e-01,\n         1.4454e-01,  6.4183e-02,  3.2808e-01, -1.9092e+00, -1.1342e+00,\n        -6.9873e-01,  2.2029e-01,  1.1792e+00,  7.5712e-01,  2.0634e+00,\n         2.7590e-01,  3.0446e-01, -2.6194e-01,  6.6055e-01,  9.9562e-01,\n         1.4326e+00,  4.1135e-02,  3.0306e-01, -1.4550e-02, -1.4967e-01,\n        -5.0803e-01,  6.0495e-01,  1.5954e-01, -1.1271e+00,  8.6592e-01,\n         8.7435e-01, -3.6850e-01,  9.3568e-01,  1.9387e-01,  2.8100e-01,\n         1.6872e+00, -1.3021e+00, -6.7141e-02, -1.7272e-01, -2.2454e+00,\n        -8.6148e-01, -2.2125e-01, -3.9981e-02,  3.7624e-02,  1.5752e-03,\n         1.0381e+00,  2.2792e+00,  8.7236e-01,  8.9530e-01,  1.0423e+00,\n        -2.9154e-01, -4.4740e-01, -5.4772e-01, -8.0006e-01, -1.2193e+00,\n         6.5850e-01, -4.8287e-01, -1.5313e-01])\n\n\nNow we animate through the residual stream.\n\n\nCode\nresidual_stream = np.zeros((13, d_model))\n\nfor layer in range(13):\n    residual_stream_layer = outputs.hidden_states[layer][0, -1, :].numpy()\n    residual_stream[layer] = residual_stream_layer\n    print(f\"Layer {layer}: Residual stream shape {residual_stream_layer.shape}\")\n\n\nLayer 0: Residual stream shape (768,)\nLayer 1: Residual stream shape (768,)\nLayer 2: Residual stream shape (768,)\nLayer 3: Residual stream shape (768,)\nLayer 4: Residual stream shape (768,)\nLayer 5: Residual stream shape (768,)\nLayer 6: Residual stream shape (768,)\nLayer 7: Residual stream shape (768,)\nLayer 8: Residual stream shape (768,)\nLayer 9: Residual stream shape (768,)\nLayer 10: Residual stream shape (768,)\nLayer 11: Residual stream shape (768,)\nLayer 12: Residual stream shape (768,)\n\n\n\n\nCode\nresidual_stream = rearrange(residual_stream, \"layer (row col) -&gt; layer row col\", row=16)\n\nresidual_stream.shape\n\n\n(13, 16, 48)\n\n\n\n\nCode\nfrom ipywidgets import interact\nimport matplotlib.pyplot as plt\n\ndef plot_layer(layer=0):\n    fig, ax = plt.subplots(1, 1, figsize=(15, 5))\n    ax.axis(False)\n    fig.set_facecolor('black')\n    ax.set_facecolor('black')\n\n    cmesh = ax.pcolormesh(residual_stream[layer], edgecolors='k', cmap='viridis', vmin=-3, vmax=3)\n    ax.set_title(f'Layer {layer}', color='white', fontsize=16)\n    plt.show()\n\ninteract(plot_layer, layer=(0, residual_stream.shape[0]-1, 1))\n\n\n\n\n\n&lt;function __main__.plot_layer(layer=0)&gt;"
  },
  {
    "objectID": "blog/posts/residual-stream/index.html",
    "href": "blog/posts/residual-stream/index.html",
    "title": "The Residual Stream",
    "section": "",
    "text": "This post explains the residual stream in transformer models in and builds towards using it for a first historic example of mechanistic interpretability - Logit Lens (nostalgebraist 2020)."
  },
  {
    "objectID": "blog/posts/residual-stream/index.html#transformers",
    "href": "blog/posts/residual-stream/index.html#transformers",
    "title": "The Residual Stream",
    "section": "Transformers",
    "text": "Transformers\nMuch of what I know about transformers comes from the excellent “A Mathematical Framework for Transformer Circuits” (Elhage et al. 2021).\nThe transformer is made of a few crucial components:\nThe transformer is made of a few crucial components:\n\nToken embedding, \\(W_{E}\\)\nResidual Stream, \\(x_{i}\\)\nAttention layer, \\(\\sum_{h \\in H} h(x_{i})\\)\nMLP Layer, \\(m(x_{i+1})\\)\nUnembedding, \\(W_{U}\\)\n\nI will give a high level overview of what each does by considering the input sequence,\n\n“The capital of the country containing Manchester is”\n\n\n\n\n\n\n\n\n\nNoteManchester\n\n\n\nGetting a sensible answer from small LLMs is still hard, GPT-2 prompted with “The capital of the country containing Lyon is” returned “the” with 30% confidence and “France” with only 4% confidence.\n\n\nWe will follow the final token “is” as this is the token from which the model will predict the next token.\nThe first step is to use the Token embedding, \\(W_{E} \\in \\mathbb{R}^{d_{model} \\times d_{vocab}}\\), which acts as a look-up table from the token “is” to the \\(d_{model}\\) vector that represents it,\n\\[\nx_{0} = W_{E} t\n\\tag{1}\\]"
  },
  {
    "objectID": "blog/posts/residual-stream/index.html#the-residual-stream",
    "href": "blog/posts/residual-stream/index.html#the-residual-stream",
    "title": "The Residual Stream",
    "section": "The Residual Stream",
    "text": "The Residual Stream\nThe residual stream is a fundamental concept in understanding how transformers process information. It is also the place much mechanistic interpretability is done.\n\n\n\n\n\n\nAnimation of the Residual Stream Across Layers\n\n\n\n\nSource: residual_stream_animation.ipynb"
  },
  {
    "objectID": "blog/posts/residual-stream/index.html#logit-lens",
    "href": "blog/posts/residual-stream/index.html#logit-lens",
    "title": "The Residual Stream",
    "section": "Logit Lens",
    "text": "Logit Lens\nWith these common tensors passing through the model we can try our hand at some early mech interp - namely applying the Logit Lens (nostalgebraist 2020).\nThe idea is simple, after the final layer of the transformer we apply an unembedding to get logits.\n\n\n\n\n\n\nNoteTuned Lens\n\n\n\n\n\nIt turns out that logit lens is not very reliable, when we apply the unembedding we find something uninformative such as the input token repeated.\nThis problem is partially solved by the Tuned Lens (Belrose et al. 2023).\nBy accounting for a non-zero bias term and allowing a change of basis we get results that better match how Logit Lens performed on GPT-2.\n\n\n\nThis allows us, in a very simple way, to see the thoughts of the model progress through the layers."
  }
]