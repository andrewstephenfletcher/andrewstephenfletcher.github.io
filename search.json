[
  {
    "objectID": "notebooks/hf.html",
    "href": "notebooks/hf.html",
    "title": "",
    "section": "",
    "text": "# Clear any existing invalid HF_TOKEN environment variable\nimport os\nif 'HF_TOKEN' in os.environ:\n    del os.environ['HF_TOKEN']\n    print(\"Cleared HF_TOKEN environment variable\")\n\n\nfrom huggingface_hub import login\nlogin()\n\n\nimport torch\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\n\nmodel_name = \"meta-llama/Llama-3.2-1B\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForCausalLM.from_pretrained(model_name)\ntokenizer.pad_token = tokenizer.eos_token\n\n\n\n\n\nimport torch.nn.functional as F\n\ninputs = tokenizer(\n    \"Fact: The capital of the country containing Manchester is\",\n    padding=True,\n    truncation=True,\n    return_tensors=\"pt\"\n)\n\nprint(f\"Tokenized {inputs['input_ids'].shape[0]} sequences with max length {inputs['input_ids'].shape[1]}.\")\n\nwith torch.no_grad():\n    outputs = model(\n        input_ids=inputs[\"input_ids\"],\n        attention_mask=inputs[\"attention_mask\"],\n        output_hidden_states=True,\n    )\n\nlast_token_logits = outputs.logits[0, -1, :]\n\nprobs = F.softmax(last_token_logits, dim=-1)\n\ntop_k = 5\ntop_probs, top_indices = torch.topk(probs, k=top_k)\n\nprint(f\"Fact: the capital of the state containing Dallas is\",)\nprint(\"-\" * 30)\nfor i in range(top_k):\n    token = tokenizer.decode(top_indices[i])\n    probability = top_probs[i].item() * 100\n    print(f\"{i+1}. {token:10} | Confidence: {probability:.2f}%\")\n\nTokenized 1 sequences with max length 11.\nFact: the capital of the state containing Dallas is\n------------------------------\n1.  London    | Confidence: 12.89%\n2.  Birmingham | Confidence: 7.81%\n3.  not       | Confidence: 6.08%\n4.  Manchester | Confidence: 5.37%\n5.  called    | Confidence: 4.74%"
  },
  {
    "objectID": "blog/index.html",
    "href": "blog/index.html",
    "title": "Blog",
    "section": "",
    "text": "Documenting my learning of AI Safety.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Residual Stream\n\n\n\nmechanistic interpretability\n\nresidual stream\n\nlatent space monitoring\n\n\n\n\n\n\n\n\n\nFeb 10, 2026\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog/posts/residual-stream/index.html",
    "href": "blog/posts/residual-stream/index.html",
    "title": "The Residual Stream",
    "section": "",
    "text": "This post discusses the residual stream in transformer models and builds towards using it for two examples of mechanistic interpretability: Logit Lens (nostalgebraist 2020) and Linear Probes (Alain and Bengio 2018)."
  },
  {
    "objectID": "blog/posts/residual-stream/index.html#transformers",
    "href": "blog/posts/residual-stream/index.html#transformers",
    "title": "The Residual Stream",
    "section": "Transformers",
    "text": "Transformers\nMuch of the description of a transformer here comes straight from the excellent “A Mathematical Framework for Transformer Circuits” (Elhage et al. 2021).\nThe transformer is made of a few crucial components:\n\nToken embedding, \\(W_{E}\\)\nResidual Stream, \\(x_{i}\\)\nAttention layer, \\(Attn(x_{i}) = \\sum_{h \\in H} h(x_{i})\\)\nMLP Layer, \\(MLP(x_{i})\\)\nUnembedding, \\(W_{U}\\)\n\nI will give a high level overview of what some of these elements do by considering the input sequence,\n\n“The capital of the country containing Manchester1 is”\n1 Getting a sensible answer from small LLMs is hard, GPT-2 prompted with “The capital of the country containing Lyon is” returned “the” with 30% confidence and “France” with only 4% confidence.\nWe will follow the final token “is” as this is the token from which the model will predict the next token.\nThe first step is to use the Token embedding, \\(W_{E} \\in \\mathbb{R}^{d_{model} \\times d_{vocab}}\\), which acts as a look-up table from the token “is”, which we represent initially by the Token index \\(t \\in \\mathbb{R}^{d_{vocab}}\\), to the \\(d_{model}\\) vector that represents it,\n\\[\nx_{0} = W_{E} t\n\\tag{1}\\]\nThis is the source of the residual stream, each process in the model adds something to this initial vector \\(x_{0}\\)2. The vector \\(x_{0}\\) starts as an isolated embedding of the token “is” but finishes as a representation capable of predicting the next token in the sequence.\n2 There has been some progress towards not using the simple additive residual stream. One such example are Hyper-Connections (Zhu et al. 2025), which allow the strength of connections between layers to be learnt during training. With the residual stream a crucial tool for safety researchers I think it would be a major set back if connection variants such as this became the norm.\n\n\nHigh level diagram of the residual stream\n\n\nMost commonly it seems a layer3 of a transformer refers to the combination of an Attention layer and an MLP layer but they add to the residual stream sequentially,\n3 (Elhage et al. 2021) also refers to this as a “residual block”.\\[\nx_{n+1} = x_{n} + Attn(x_{n}) + MLP(x_{n} + Attn(x_{n}))\n\\tag{2}\\]\nAttention heads move information from the residual streams of other tokens in the sequence. For example in our example if we are going to answer the question,\n\n“The capital of the country containing Manchester is”\n\nour final representation \\(x_{-1}\\) is going to need to capture the multi-hop reasoning that the country containing Manchester is the United Kingdom and hence the capital is London we need to move information from these other tokens.\nIt must also know these geographical facts, research suggests that this is captured somewhere within the MLP layers (Nanda et al. 2024)."
  },
  {
    "objectID": "blog/posts/residual-stream/index.html#why-residuals",
    "href": "blog/posts/residual-stream/index.html#why-residuals",
    "title": "The Residual Stream",
    "section": "Why residuals?",
    "text": "Why residuals?\nThere are a few reasons that this additive approach is favoured but their inclusion is likely a legacy of the Residual Neural Network (ResNet) (He et al. 2015). This paper suggested a residual stream formulation,\n\\[\nx + f(x)\n\\tag{3}\\]\nwhich has since also become known as a skip connection. The layers of the network return a “residual mapping” \\(f(x)\\) which is added to the main input. From their paper the primary motivation was to combat the degradation problem, where deeper networks have higher training and test error. This should be slightly surprising as we might expect a model with 20 layers can be replicated within a model of 50 layers.\nIt turns out that for networks without a residual stream the correlation between gradients decays exponentially (Balduzzi et al. 2018), that is to say at a point \\(x\\) the gradient \\(\\nabla f(x)\\) might be almost random compared to a near by point \\(x + \\delta\\) with gradient \\(\\nabla f(x + \\delta)\\). If the gradients are almost random gradient descent is too, we set off down the slope only to immediately find it increase again. In contrast, with skip connections the correlation between gradients decays sub-linearly.\nA subtly different additional benefit to using a residual stream is that we also solve the vanishing gradient problem, where by in a deep network backpropagation will involve many applications of the chain rule such that if any of the gradients are small the total update to the weights will vanish.\nFollowing this 3Blue1Brown explainer (Sanderson 2017) we consider a very simple network with single neuron layers, connected in sequence. Let’s say every layer consists of,\n\\[\nf(x_{i}) = \\sigma(W x_{i}  + b)\n\\tag{4}\\]\nThe sigmoid function4, \\(\\sigma\\), is defined as,\n4 ReLU and GELU activation functions are designed to also combat the vanishing gradient problem.\\[\n\\sigma(z) = \\frac{e^z}{1+e^z}\n\\tag{5}\\]\nIts derivative, \\(\\sigma'(z) = \\sigma(z)(1 - \\sigma(z))\\), is bounded within the interval \\((0, 0.25]\\). Hence, when we calculate the gradient of the loss, \\(\\nabla \\mathcal{L}\\), in backpropagation this term will reduce the resulting value by at least a factor of 4 each layer. As we update the weights according to \\(-\\eta \\nabla \\mathcal{L}\\) when the gradient vanishes we stop learning.\nWith a residual stream there will always be a non-zero gradient,\n\\[\nx_{i+1} = x_{i} + f(x_{i})\n\\tag{6}\\]\n\\[\n\\frac{\\partial(x_{i+1})}{\\partial x_{i}} = 1 + f'(x_{i})\n\\tag{7}\\]\nThe constant term \\(1\\) means even with repeated applications of the chain rule it is always possible to trace through the network to get a non-zero update to earlier layers."
  },
  {
    "objectID": "blog/posts/residual-stream/index.html#the-residual-stream-in-mechanistic-interpretability",
    "href": "blog/posts/residual-stream/index.html#the-residual-stream-in-mechanistic-interpretability",
    "title": "The Residual Stream",
    "section": "The Residual Stream in Mechanistic Interpretability",
    "text": "The Residual Stream in Mechanistic Interpretability\nWith this consistent \\(d_{model}\\) dimension vector flowing through the model we have an obvious place to inspect the model’s thoughts. As each layer refines the representation of the “is” token in preparation for predicting the next we can explore two ways to interpret this process:\n\nLogit Lens (nostalgebraist 2020)\nLinear Probes (Alain and Bengio 2018)\n\nIn the rest of this post I have some experiments that use these techniques to illustrate their value.\n\nLogit Lens\nThe idea beyhind Logit Lens is simple, after the final layer, \\(x_{-1}\\), of the transformer we apply an unembedding to get logits,\n\\[\nT(t) = W_{U} x_{-1}\n\\tag{8}\\]\nwhich allow us to predict words. For our input sequence GPT-2 returned:\n\nLondon with 13% confidence\nBirmingham with 8% confidence\nnot with 6% confidence\n…\n\nWe can however apply the unembedding to intermediate vectors in the residual stream, getting a crude understanding of what the model is thinking of at that point. This allows us, in a very simple way, to see the thoughts of the model progress through the layers.\n\n\n\nHigh level diagram of Logit Lens\n\n\n\n\n\n\n\n\nNoteTuned Lens\n\n\n\n\n\nIt turns out that logit lens is not very reliable, when we apply the unembedding we find something uninformative such as the input token repeated.\nThis problem is partially solved by the Tuned Lens (Belrose et al. 2023).\nBy accounting for a non-zero bias term and allowing a change of basis we get results that better match how Logit Lens performed on GPT-2.\n\n\n\n\n\nLinear Probes\nLinear probes approach the interpretability problem in a different way. Imagine we have two classes of inputs, the linear probe is a classifier trained on the residual stream vectors that learns to distinguish the classes. Examples might include:\n\nProper punctuation vs. ALL CAPS\nNatural language vs. HTML\nHarmless text vs. Harmful text\n\nThe first case we might imagine is quite simple to learn: there is a simple pattern-matching problem for the model to spot between \"Hello, can I help you?\" and \"HELLO, CAN I HELP YOU?\". Likewise, the second is hopefully quite easy to discern, but perhaps requires some more thinking: \"The main header of the page says Hello.\" looks very different to \"&lt;h1 class='main-header'&gt; Hello &lt;/h1&gt;\", but it requires more knowledge to consistently separate the two.\nFinally, examples of harmless and harmful text might be really tricky to separate, requiring genuine semantic understanding. For example, \"There is a bug in your code, so you should **refactor the function.**\" is quite harmless whereas \"There is a bug in your code, so you should **disable the firewall.**\" could be catastrophic.\n\n\n\nHigh level diagram of Linear Probes"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Andrew Stephen Fletcher",
    "section": "",
    "text": "I am a Data Scientist with an interest in AI Safety research. I am keen to learn more about many areas but have started diving into Latent Space Monitoring. This website has a blog, mainly focused on explaining AI safety techniques as I learn them."
  },
  {
    "objectID": "index.html#bio",
    "href": "index.html#bio",
    "title": "Andrew Stephen Fletcher",
    "section": "",
    "text": "I am a Data Scientist with an interest in AI Safety research. I am keen to learn more about many areas but have started diving into Latent Space Monitoring. This website has a blog, mainly focused on explaining AI safety techniques as I learn them."
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Andrew Stephen Fletcher",
    "section": "Education",
    "text": "Education\nUniversity of Exeter | Data Science MSc\nDeep learning and PyTorch | 2023 - present\nUniversity of Oxford | Physics MPhys\nFocus on Astrophysics | 2019 - 2023"
  },
  {
    "objectID": "index.html#experience",
    "href": "index.html#experience",
    "title": "Andrew Stephen Fletcher",
    "section": "Experience",
    "text": "Experience\nBBC Studios | Data Science\nML research predicting TV viewing | 2023 - present\nBlueDot | Technical AI Safety Course\nCourse introducing ideas in technical AI safety | 2025"
  },
  {
    "objectID": "docs/blog/posts/residual-stream/residual_stream_animation.html",
    "href": "docs/blog/posts/residual-stream/residual_stream_animation.html",
    "title": "",
    "section": "",
    "text": "import numpy as np\n\n\nd_model = 768\nn_layers = 12\n\nresidual_stream = np.random.randn(n_layers, d_model)\n\nresidual_stream.shape\n\n(12, 768)\n\n\nLet’s use Einops to rearrange this into a nice array to visualize.\n\nfrom einops import rearrange, reduce, repeat\n\nresidual_stream = rearrange(residual_stream, \"layer (row col) -&gt; layer row col\", row=16)\n\nresidual_stream.shape\n\n(12, 16, 48)\n\n\nNow we do the simplest plot of such a tensor.\n\nimport matplotlib.pyplot as plt\n\nplt.imshow(residual_stream[0], cmap='viridis')\nplt.title(\"Residual Stream at Layer 0\")\nplt.show()\n\n\n\n\n\n\n\n\nWe want to make this much prettier for the blog.\n\nfig, ax = plt.subplots(1,1, figsize=(15,5))\nax.axis(False)\nfig.set_facecolor('black')\nax.set_facecolor('black')\n\ncmesh = ax.pcolormesh(residual_stream[0], edgecolors='k', cmap='viridis', vmin=-3, vmax=3)\n\n\n\n\nAnimation of the Residual Stream Across Layers\n\n\n\n\nNow we can think about animating this.\n\nfrom matplotlib.animation import FuncAnimation\n\ndef anim_function(frame_num):\n    cmesh.set_array(residual_stream[frame_num,:,:])\n    return cmesh,\n\nanim = FuncAnimation(fig, anim_function, frames=np.arange(residual_stream.shape[0]), interval=30)\n\nfrom IPython.display import HTML\nHTML(anim.to_jshtml())\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\nNow lets look to do something with actual model activations!\n\nfrom huggingface_hub import login\nlogin()\n\n\nimport torch\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\n\nmodel_name = \"gpt2\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForCausalLM.from_pretrained(model_name)\ntokenizer.pad_token = tokenizer.eos_token\n\n\n\n\n\n\n\nGPT2LMHeadModel LOAD REPORT from: gpt2\nKey                  | Status     |  | \n---------------------+------------+--+-\nh.{0...11}.attn.bias | UNEXPECTED |  | \n\nNotes:\n- UNEXPECTED    :can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n\n\n\ninputs = tokenizer(\n    \"Paris is the capital of\",\n    padding=True,\n    truncation=True,\n    return_tensors=\"pt\"\n)\n\nprint(f\"Tokenized {inputs['input_ids'].shape[0]} sequences with max length {inputs['input_ids'].shape[1]}.\")\n\nTokenized 1 sequences with max length 5.\n\n\n\nwith torch.no_grad():\n    outputs = model(\n        input_ids=inputs[\"input_ids\"],\n        attention_mask=inputs[\"attention_mask\"],\n        output_hidden_states=True,\n    )\n\n\ntype(outputs.hidden_states)\n\ntuple\n\n\n\noutputs.hidden_states[12][0, -1, :]\n\ntensor([ 3.9707e-01,  6.5592e-01, -1.0789e-01, -5.1339e-01,  2.2478e-01,\n        -3.5340e-01,  2.9402e+00,  5.0266e-01, -1.1648e-01, -3.3925e-01,\n        -1.4641e-01,  1.3185e-01,  5.6856e-01, -2.4193e-01,  2.3383e-01,\n        -6.1204e-01, -1.6270e-01,  2.6729e-01,  1.0813e-01, -3.3550e+00,\n         3.8122e-01,  3.1480e-01,  3.6961e-01, -1.1843e-01, -4.1384e-02,\n         2.7716e-01, -6.5405e-01, -6.8845e-01,  1.7058e-01,  2.3255e-01,\n         2.1136e-02, -2.7776e-01,  1.7016e-01,  3.5261e-01,  6.2866e-01,\n        -2.2970e-01,  5.0996e+01, -3.4832e-01, -4.9283e-01,  1.6009e-01,\n        -2.5912e-01, -4.3954e-02, -6.6652e-02,  1.7371e-02, -4.9989e-02,\n         7.7331e-02, -2.0900e-01, -5.2491e-01, -9.1295e-01, -7.5307e-02,\n        -5.9557e-02, -3.5249e-01,  9.1986e-02, -4.4967e-02,  1.7474e-01,\n         1.0622e+00, -3.1931e-02, -2.3144e-01,  1.4521e-01, -4.0620e-01,\n        -5.8457e-01,  1.4042e-02,  1.0694e-01, -1.2151e-01, -1.1069e+00,\n         4.4808e-01, -1.6879e-01,  4.8419e-02, -1.2701e+00,  1.9134e-01,\n        -7.3997e-01, -6.9388e-01,  9.3711e-03, -3.0020e-01, -2.9383e-02,\n         1.1450e-01,  2.2709e-01, -6.2942e-01,  3.4850e-01,  4.6560e-01,\n         2.9459e-01, -2.3642e-01,  4.6218e-01, -7.3631e-02,  4.3862e-01,\n         1.2286e-01,  9.8999e-01, -1.0245e+00,  2.4983e-01, -1.2601e-01,\n         4.3485e-01,  6.3421e-01,  3.8452e-01,  9.8958e-03, -6.1150e-02,\n        -2.8366e-01, -3.5584e-01, -3.4806e-01,  4.6458e-02,  1.0344e-01,\n        -1.7640e-01,  2.6008e-01,  3.0842e-01, -5.9029e-01,  6.2168e-02,\n         8.0234e-02, -2.1006e-01, -1.3377e+00,  4.7618e-01, -2.3790e-01,\n         5.6921e-01, -1.8896e-01,  8.6591e-02,  1.3231e-02,  1.2710e-01,\n        -5.3515e-01,  3.2699e-01, -2.2347e-01,  2.8715e-01, -1.1292e+00,\n         7.7704e-02,  5.1702e-01,  2.5250e-02,  8.0246e-01, -2.2748e-01,\n         4.8657e-01,  4.7917e-01,  5.0834e-01, -1.8833e-01,  5.0228e-01,\n        -3.7779e-01, -3.9931e-01,  2.4244e-01,  2.1779e-01, -1.0248e-01,\n         4.3215e-01,  1.9822e-01, -4.4591e-01,  5.6154e-01,  3.0105e-01,\n        -4.6189e-01, -8.0389e-01,  9.8432e-01, -3.1944e-01,  9.4833e-02,\n         1.1400e-01, -1.5258e-01,  8.6682e-02, -5.9506e-03,  1.0061e+00,\n         3.5015e-01, -5.4344e-01, -1.4929e-02,  2.9061e-01,  7.7716e-01,\n         5.7593e-02,  4.1433e-01,  2.0678e-01,  1.1295e-01, -3.3525e-01,\n        -6.4733e-01, -2.0853e-01, -6.8152e-01, -2.3764e-01, -7.2244e-03,\n         5.3895e-02, -1.7540e-02, -3.5193e+00, -2.7689e-01, -1.4060e-01,\n         2.2860e-01, -2.3910e-01,  1.4758e-01,  4.6928e-01, -4.1897e-01,\n        -8.1610e-01,  6.8833e-01, -5.3819e-01, -5.4749e-02, -1.4693e-01,\n         1.5520e-01,  3.4751e-01, -1.0811e-02, -1.1496e-01, -3.7802e-01,\n        -5.4832e-02, -1.7603e-01, -1.5183e-01, -3.5338e-03, -1.5314e-02,\n        -1.0327e-01, -4.9390e-01, -9.5211e-03,  2.2363e-01, -8.6061e-02,\n        -1.6430e+00,  4.8663e-01,  2.2926e-01, -1.5008e-01,  4.6846e-03,\n         1.8621e-01,  5.8974e-01, -2.3210e-01, -3.8068e-02,  5.2106e-02,\n        -2.1625e-01,  1.3113e-01, -1.6528e-01, -3.0899e-01, -8.6106e-02,\n         1.1730e-01, -2.2622e-01, -3.6722e-01, -1.5751e-01, -3.6578e-02,\n        -3.0102e-01, -4.9017e-02, -4.6044e-01,  4.7928e-01,  3.5405e-02,\n         9.5526e-02, -1.9290e-01,  3.5486e-01,  3.5565e-01, -4.3436e-01,\n        -3.7214e-01,  3.7490e-01, -1.4289e-01,  1.4892e-01,  4.4548e-01,\n        -6.1742e-02,  3.3417e-01,  1.5622e+00, -1.6550e-01, -9.5622e-02,\n        -3.1609e-01,  3.5710e-01,  1.5547e-01,  3.7913e-01, -4.5316e-01,\n        -3.0411e-01,  6.3645e-01,  4.6493e-01, -2.7021e-01,  2.8007e-01,\n         3.5020e-01,  4.3037e-01, -2.0467e-01, -1.7361e-01,  5.0707e-02,\n         5.2277e-01, -1.6470e-01,  2.9059e-01,  9.7539e-02, -8.1670e-02,\n         3.0347e-01,  3.0409e-01, -1.9271e-01, -3.8301e-01,  5.5685e-01,\n        -2.9989e-01,  7.5335e-01, -1.9442e-01, -8.1730e-01, -5.7642e-02,\n         4.5157e-01, -1.0122e+00,  3.4106e-02,  3.7177e-01,  4.8461e-01,\n         1.0395e+00,  3.5976e-01,  1.9491e-01, -1.8765e-01,  9.0858e-02,\n        -1.2970e-01, -6.9582e-02, -3.3006e-01,  1.2637e-01, -1.4938e-01,\n         1.7854e-01, -3.3438e-02,  2.9249e-01, -6.0153e-02, -3.9808e-01,\n        -4.7156e-02,  1.6853e-01, -2.4003e-02, -9.1483e-02,  3.4247e-01,\n         2.2795e-01,  3.3932e-01, -3.3874e-01, -5.3320e-02, -1.2861e-02,\n        -1.2411e-02,  3.7387e-02,  5.8254e-02, -2.5397e-01,  5.2348e-01,\n         8.6658e-01, -3.5760e-01,  1.3084e-01, -1.1010e-01,  5.1624e-01,\n         6.0349e-01, -4.8093e-01,  1.6971e-01,  1.2630e+00, -2.6303e-01,\n         1.8936e-01,  2.1825e-01,  2.9491e-02, -3.4005e-01, -4.3871e+01,\n         4.7595e-02, -1.4228e-01, -1.0846e-01, -1.5160e-01,  1.0329e-01,\n         3.7053e-01, -1.2320e-02,  3.1999e-01,  5.6906e-02,  3.0835e-01,\n         2.0784e-01, -3.3139e-01, -4.5700e-01, -1.5465e-01,  1.6962e-01,\n        -3.5235e-01, -7.5174e-03,  4.5752e-01,  4.0825e-01, -1.1673e-01,\n        -1.0488e-02,  2.5212e-02, -1.6757e-01,  2.3002e-01, -1.8673e-02,\n        -1.7697e-01, -2.1341e-01, -6.6391e-01, -1.8274e-01,  7.0124e-01,\n         2.5572e-01,  1.5160e-01, -2.0538e-01,  1.8113e-01, -4.6497e-02,\n        -2.5627e-01, -4.6529e-01,  1.9979e-01, -1.2916e-01, -3.4473e-01,\n        -4.8907e-01, -3.6988e-01,  1.0921e-01, -1.2943e-01, -1.2346e-01,\n         8.8096e-02,  1.2546e+00,  6.3094e+00, -2.5674e-01, -4.3520e-01,\n        -2.3859e+00,  4.8746e-01, -3.9125e-02, -4.1557e-02, -2.7922e-01,\n         8.7475e-02,  2.1376e-01, -6.5235e-02, -1.2277e+00, -2.0121e+01,\n         4.7794e-01,  3.3857e-01,  1.3460e-01,  4.3976e-01,  1.7539e-01,\n         2.3180e-01, -3.4298e-01,  2.6690e-01, -3.0966e-01, -8.0459e-01,\n         1.0486e-01,  2.3068e-01, -2.7034e-01, -7.2113e-02,  1.2232e+00,\n        -3.3541e-02,  1.2416e-01, -5.4055e-02,  3.2458e-01, -2.6819e-01,\n        -2.7736e-01, -1.0285e-01, -3.2138e-01,  4.5720e-01,  1.7563e-01,\n        -5.7128e-02,  1.5178e-01, -4.0476e-01,  5.8006e-02,  3.9195e-02,\n        -2.5981e-01,  2.0811e-01, -2.8853e-01,  6.6633e+00, -5.7252e-01,\n        -5.5131e-02,  7.3943e-02,  3.7546e-01,  5.8285e-02, -6.3121e-01,\n        -5.0900e-01, -5.1948e-02, -1.1226e-01, -1.6612e-01, -1.6518e-01,\n         4.8815e-01,  1.6613e-01, -4.5851e-01, -5.6316e-01, -3.2561e-02,\n        -1.4305e-01, -2.9152e-01, -6.2530e-01, -1.1286e-01,  6.0920e-03,\n         7.0946e+01,  4.8999e-01,  1.3975e-01, -1.2525e-01, -1.5065e-01,\n         1.6868e-01, -2.7682e-02, -4.1910e-01,  2.6702e-01, -1.3076e+00,\n         4.4607e-01,  1.2542e-01, -2.8018e+00,  1.4158e-01, -5.2851e-01,\n        -3.3754e-01,  1.9284e-02,  1.0982e+00,  6.1203e-02,  2.5273e-01,\n        -6.5044e-01, -1.6463e-01, -3.6856e-01,  7.3381e-02,  2.8394e-01,\n         7.1713e-01, -4.5587e-01, -3.6499e-01, -3.1927e-01,  2.5299e-01,\n         3.1554e-01, -3.9655e-01, -1.6431e-01, -3.2882e-01,  4.8321e-01,\n         2.6438e-02,  3.2431e-01, -7.3670e-01,  3.7471e-01,  2.6125e-01,\n         1.1955e-01, -2.1661e-01,  4.1328e-01,  1.6487e-01,  4.8600e-02,\n        -1.4378e-02, -7.9637e-02, -4.6863e-01, -4.1781e-01,  1.7027e+00,\n        -8.9309e-01,  1.2432e+00,  2.1844e-01,  5.7696e-02,  1.4689e-01,\n         1.5076e-01,  5.9482e-02, -6.2378e-01, -2.9110e-01, -1.6801e-01,\n        -3.6049e-01, -3.8028e-02, -2.2511e-01, -5.7139e-01, -4.8377e-01,\n        -4.3101e-02,  1.8708e+02, -2.1507e-01,  1.9170e-01, -3.0552e-02,\n         2.2827e-01,  1.0583e-01, -7.0139e-02, -2.7798e+00,  1.4771e-01,\n         8.5176e-02, -2.1687e-01,  3.3596e-01,  5.2070e-01,  1.1699e-01,\n         9.5625e-02,  7.2405e-02, -7.4354e-01, -4.1796e-01, -3.1036e-01,\n         1.9051e-01,  1.3422e-01,  1.3123e-02,  6.9384e-02,  4.9266e-01,\n        -3.0280e-01,  4.1873e-01,  3.8501e-01,  5.0008e-02, -4.1961e-01,\n        -9.2081e-01, -8.8505e-01, -4.4598e-01,  3.2327e-01,  3.3958e-01,\n         2.7451e-01,  1.5717e-02, -1.3682e-01, -1.1711e-01,  8.5470e-01,\n         2.0400e-01, -3.2440e-03, -6.6013e-01, -9.5547e-01,  1.1471e-01,\n        -2.7788e-01, -2.0668e-01,  2.4634e-01,  6.9303e-01, -4.9175e-01,\n         5.9871e-01,  2.5664e-01, -3.5525e-02, -6.6084e-01,  3.5962e-03,\n         7.7517e-01,  3.3645e-01,  4.1101e-01,  6.3882e-01, -1.1079e+00,\n         3.5268e-01, -1.6977e-01, -3.6987e-02,  2.5442e-01,  3.5130e-01,\n        -3.1887e-02, -4.1854e-01,  1.6195e-01, -1.2116e-01,  3.4556e-01,\n        -3.1018e-01, -1.4006e-01, -2.2971e-02, -2.4656e-01, -1.3791e-02,\n        -7.8256e-02,  1.3936e-01,  2.5287e-01,  1.2679e-01,  1.0444e-02,\n        -7.2022e-01,  6.0788e-02,  1.3312e-01, -5.9214e-01, -2.5595e-02,\n        -1.9300e-01,  2.0226e-01,  8.7149e-02, -2.8428e-01, -7.0516e-02,\n         2.0947e-01, -2.4657e-01, -2.4485e-01, -9.9435e-02,  3.1029e-01,\n        -3.1992e-02, -6.6761e-02, -6.7534e-01, -8.6753e-01, -6.0732e-02,\n         1.5726e-01,  7.2841e-02, -1.3594e-01,  2.1770e-01, -1.9269e-01,\n         7.0538e-02,  2.4697e-01, -2.1211e-01,  3.9387e-01, -1.1869e-01,\n         3.3987e-01, -2.5016e-01,  3.6958e-02,  1.6831e+00,  1.3615e-02,\n        -1.7321e-01,  5.6813e-01,  6.5152e-01, -1.0398e-01,  3.8231e-01,\n         3.3899e-01,  8.4053e-01,  1.7321e-01,  2.9557e-01,  4.3555e-01,\n        -3.8328e-01,  7.0625e-01,  1.4007e-01,  5.9916e-01,  3.2180e-01,\n         2.8273e-01,  5.9825e-02,  9.4940e-01, -4.5199e-02,  2.8532e-01,\n        -7.0141e-02,  5.2700e-02, -1.2425e-01, -4.9037e-02, -3.8386e-01,\n        -6.8675e-01,  5.6606e-02,  1.1794e-01, -4.0015e-01,  1.5555e-01,\n         4.9732e-01, -2.5473e-02,  6.1942e-01, -4.3914e-01,  3.6841e-01,\n        -1.0106e+00,  5.7044e-01,  6.3400e-01,  1.8109e-01, -1.2689e+00,\n         3.0568e-01, -2.4669e-01, -4.7047e-01, -6.9111e-01, -1.8980e-01,\n         9.3604e-01, -2.0410e-01, -1.1872e-01, -2.7357e-02,  2.3875e-01,\n         3.1092e-01,  1.1390e-02, -2.4784e-01, -7.8412e-03, -6.9789e-01,\n         1.5111e-01, -2.7125e-01, -2.5387e-01, -1.8569e-01,  5.4281e-01,\n        -1.2238e-01,  5.8334e-01, -1.0270e-01, -6.6581e-01,  5.0467e-02,\n         2.2914e-01, -6.2707e-01,  3.1402e-01, -2.5495e-01,  2.1849e-01,\n        -8.2420e-01,  1.0366e-01, -6.9238e-02, -1.6138e-01,  2.4286e-02,\n         8.9909e-02, -2.2955e-02,  1.1647e-01,  3.7806e-01,  3.2999e-01,\n         9.7268e-01,  2.0536e-01,  3.2675e-01,  1.2438e-01,  9.5249e-02,\n         2.0198e-01, -1.1161e-01, -1.8637e-01, -5.8571e-02, -4.2029e-01,\n        -7.9599e-02,  1.5202e-01,  2.0047e-01, -1.0811e+00, -6.1192e-01,\n        -1.4036e-01,  5.7603e-01, -1.3407e-01, -1.2577e-01, -3.3293e-01,\n        -1.4304e-01, -5.7476e-01, -3.0210e-01, -1.0654e-01,  1.8689e-01,\n        -1.1735e-01,  2.6910e-02,  3.3609e-01, -3.8913e-01,  1.3305e-02,\n        -9.7757e-01, -5.0708e-01, -3.9805e-01, -2.5544e-01,  5.2961e-01,\n         7.5593e-01,  2.7601e-01, -1.0440e+00,  4.2858e-01, -3.3402e-01,\n         4.9627e-01, -5.5644e-02,  2.6034e-01, -3.1860e-01,  1.9822e-01,\n        -6.6199e-01,  5.5858e-01, -1.4615e-01, -1.3237e-01, -4.9860e-02,\n         6.2007e-02, -1.5592e-02,  1.9362e-01, -3.9611e-01, -5.7654e-01,\n        -1.5250e+00, -1.2473e-01,  1.1547e-01,  1.7411e-02, -4.1657e-01,\n        -3.4960e-02,  3.0048e-01, -3.1938e-01,  4.4102e-01, -6.5498e-01,\n         3.7197e-01, -1.3987e-01,  1.6034e-01, -6.5139e-01,  3.1342e-01,\n        -2.8109e-01,  1.6483e-01,  1.8485e-01, -7.5067e-01,  1.2059e-01,\n         2.5470e-01, -8.5622e-02,  4.0347e-02])\n\n\nNow we animate through the residual stream.\n\nresidual_stream = np.zeros((13, d_model))\n\nfor layer in range(13):\n    residual_stream_layer = outputs.hidden_states[layer][0, -1, :].numpy()\n    residual_stream[layer] = residual_stream_layer\n    print(f\"Layer {layer}: Residual stream shape {residual_stream_layer.shape}\")\n\nLayer 0: Residual stream shape (768,)\nLayer 1: Residual stream shape (768,)\nLayer 2: Residual stream shape (768,)\nLayer 3: Residual stream shape (768,)\nLayer 4: Residual stream shape (768,)\nLayer 5: Residual stream shape (768,)\nLayer 6: Residual stream shape (768,)\nLayer 7: Residual stream shape (768,)\nLayer 8: Residual stream shape (768,)\nLayer 9: Residual stream shape (768,)\nLayer 10: Residual stream shape (768,)\nLayer 11: Residual stream shape (768,)\nLayer 12: Residual stream shape (768,)\n\n\n\nresidual_stream = rearrange(residual_stream, \"layer (row col) -&gt; layer row col\", row=16)\n\nresidual_stream.shape\n\n(13, 16, 48)\n\n\n\nfrom ipywidgets import interact, interactive, IntSlider, VBox, HBox, Output\nimport matplotlib.pyplot as plt\n\noutput = Output()\n\ndef plot_layer(layer=0):\n    with output:\n        output.clear_output(wait=True)\n        fig, ax = plt.subplots(1, 1, figsize=(15, 5))\n        ax.axis(False)\n        fig.set_facecolor('white')\n        ax.set_facecolor('white')\n\n        cmesh = ax.pcolormesh(residual_stream[layer], edgecolors='white', cmap='viridis', vmin=-3, vmax=3)\n        ax.set_title(f'Layer {layer}', color='black', fontsize=16)\n        plt.show()\n\nslider = IntSlider(min=0, max=residual_stream.shape[0]-1, step=1, value=0, description='Layer:')\nslider.observe(lambda change: plot_layer(change['new']), names='value')\n\n# Initial plot\nplot_layer(0)\n\n# Display with slider below and centered\nfrom ipywidgets import Layout\ndisplay(VBox([output, HBox([slider], layout=Layout(justify_content='center'))],\n             layout=Layout(background_color='white')))"
  },
  {
    "objectID": "projects/safety-viz.html",
    "href": "projects/safety-viz.html",
    "title": "Reward Misspecification Plot",
    "section": "",
    "text": "Here is a quick Python test to verify my interactive elements:\nimport matplotlib.pyplot as plt import numpy as np\nx = np.linspace(0, 10, 100) y = np.exp(x / 3) # Exponential ‘risk’ plot\nplt.plot(x, y, color=‘red’) plt.title(“Agent Risk Profile”) plt.show()"
  },
  {
    "objectID": "posts/paper-title/index.html#abstract",
    "href": "posts/paper-title/index.html#abstract",
    "title": "Can quantum-mechanical description of physical reality be considered complete?",
    "section": "Abstract",
    "text": "Abstract\nIn a complete theory there is an element corresponding to each element of reality. A sufficient condition for the reality of a physical quantity is the possibility of predicting it with certainty, without disturbing the system. In quantum mechanics in the case of two physical quantities described by non-commuting operators, the knowledge of one precludes the knowledge of the other. Then either (1) the description of reality given by the wave function in quantum mechanics is not complete or (2) these two quantities cannot have simultaneous reality. Consideration of the problem of making predictions concerning a system on the basis of measurements made on another system that had previously interacted with it leads to the result that if (1) is false then (2) is also false. One is thus led to conclude that the description of reality as given by a wave function is not complete."
  },
  {
    "objectID": "posts/paper-title/index.html#links",
    "href": "posts/paper-title/index.html#links",
    "title": "Can quantum-mechanical description of physical reality be considered complete?",
    "section": "Links",
    "text": "Links\nPublished paper"
  },
  {
    "objectID": "posts/news-title/index.html",
    "href": "posts/news-title/index.html",
    "title": "News item",
    "section": "",
    "text": "About the news"
  },
  {
    "objectID": "posts/news-title/index.html#summary",
    "href": "posts/news-title/index.html#summary",
    "title": "News item",
    "section": "",
    "text": "About the news"
  },
  {
    "objectID": "projects/index.html",
    "href": "projects/index.html",
    "title": "AI Safety Projects",
    "section": "",
    "text": "Interactive experiments and code visualizations.\n\n\n\n\n\n\n\n\n\n\n\n\nReward Misspecification Plot\n\n\nA visualization of agent behavior under faulty reward functions.\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Projects",
    "section": "",
    "text": "Order By\n      Default\n      \n      \n      \n        Title\n      \n      \n        Team\n      \n      \n        Funder\n      \n      \n        Description\n      \n      \n        Start\n      \n      \n        End\n      \n      \n        Funding\n      \n    \n  \n    \n      \n      \n    \n\n\n\n\n\n\n \n\n\n\nTitle\n\n\n\nTeam\n\n\n\nFunder\n\n\n\nDescription\n\n\n\nFunding\n\n\n\nStart\n\n\n\nEnd\n\n\n\n\n\n\n\n\n\n\n\nExploring \n\n\nAcademic Website\n\n\nFunder\n\n\nThe goal of this project is to investigate .\n\n\n$0\n\n\n2024\n\n\n2025\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "docs/blog/posts/residual-stream/residual_stream_animation.out.html",
    "href": "docs/blog/posts/residual-stream/residual_stream_animation.out.html",
    "title": "",
    "section": "",
    "text": "import numpy as np\n\n\nd_model = 768\nn_layers = 12\n\nresidual_stream = np.random.randn(n_layers, d_model)\n\nresidual_stream.shape\n\n(12, 768)\n\n\nLet’s use Einops to rearrange this into a nice array to visualize.\n\nfrom einops import rearrange, reduce, repeat\n\nresidual_stream = rearrange(residual_stream, \"layer (row col) -&gt; layer row col\", row=16)\n\nresidual_stream.shape\n\n(12, 16, 48)\n\n\nNow we do the simplest plot of such a tensor.\n\nimport matplotlib.pyplot as plt\n\nplt.imshow(residual_stream[0], cmap='viridis')\nplt.title(\"Residual Stream at Layer 0\")\nplt.show()\n\n\n\n\n\n\n\n\nWe want to make this much prettier for the blog.\n\nfig, ax = plt.subplots(1,1, figsize=(15,5))\nax.axis(False)\nfig.set_facecolor('black')\nax.set_facecolor('black')\n\ncmesh = ax.pcolormesh(residual_stream[0], edgecolors='k', cmap='viridis', vmin=-3, vmax=3)\n\n\n\n\nNow we can think about animating this.\n\nfrom matplotlib.animation import FuncAnimation\n\ndef anim_function(frame_num):\n    cmesh.set_array(residual_stream[frame_num,:,:])\n    return cmesh,\n\nanim = FuncAnimation(fig, anim_function, frames=np.arange(residual_stream.shape[0]), interval=30)\n\nfrom IPython.display import HTML\nHTML(anim.to_jshtml())\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\nNow lets look to do something with actual model activations!\n\nfrom huggingface_hub import login\nlogin()\n\n\nimport torch\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\n\nmodel_name = \"gpt2\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForCausalLM.from_pretrained(model_name)\ntokenizer.pad_token = tokenizer.eos_token\n\n\n\n\n\n\n\nGPT2LMHeadModel LOAD REPORT from: gpt2\nKey                  | Status     |  | \n---------------------+------------+--+-\nh.{0...11}.attn.bias | UNEXPECTED |  | \n\nNotes:\n- UNEXPECTED    :can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n\n\n\ninputs = tokenizer(\n    \"Paris is the capital of\",\n    padding=True,\n    truncation=True,\n    return_tensors=\"pt\"\n)\n\nprint(f\"Tokenized {inputs['input_ids'].shape[0]} sequences with max length {inputs['input_ids'].shape[1]}.\")\n\nTokenized 1 sequences with max length 5.\n\n\n\nwith torch.no_grad():\n    outputs = model(\n        input_ids=inputs[\"input_ids\"],\n        attention_mask=inputs[\"attention_mask\"],\n        output_hidden_states=True,\n    )\n\n\ntype(outputs.hidden_states)\n\ntuple\n\n\n\noutputs.hidden_states[12][0, -1, :]\n\ntensor([ 3.9707e-01,  6.5592e-01, -1.0789e-01, -5.1339e-01,  2.2478e-01,\n        -3.5340e-01,  2.9402e+00,  5.0266e-01, -1.1648e-01, -3.3925e-01,\n        -1.4641e-01,  1.3185e-01,  5.6856e-01, -2.4193e-01,  2.3383e-01,\n        -6.1204e-01, -1.6270e-01,  2.6729e-01,  1.0813e-01, -3.3550e+00,\n         3.8122e-01,  3.1480e-01,  3.6961e-01, -1.1843e-01, -4.1384e-02,\n         2.7716e-01, -6.5405e-01, -6.8845e-01,  1.7058e-01,  2.3255e-01,\n         2.1136e-02, -2.7776e-01,  1.7016e-01,  3.5261e-01,  6.2866e-01,\n        -2.2970e-01,  5.0996e+01, -3.4832e-01, -4.9283e-01,  1.6009e-01,\n        -2.5912e-01, -4.3954e-02, -6.6652e-02,  1.7371e-02, -4.9989e-02,\n         7.7331e-02, -2.0900e-01, -5.2491e-01, -9.1295e-01, -7.5307e-02,\n        -5.9557e-02, -3.5249e-01,  9.1986e-02, -4.4967e-02,  1.7474e-01,\n         1.0622e+00, -3.1931e-02, -2.3144e-01,  1.4521e-01, -4.0620e-01,\n        -5.8457e-01,  1.4042e-02,  1.0694e-01, -1.2151e-01, -1.1069e+00,\n         4.4808e-01, -1.6879e-01,  4.8419e-02, -1.2701e+00,  1.9134e-01,\n        -7.3997e-01, -6.9388e-01,  9.3711e-03, -3.0020e-01, -2.9383e-02,\n         1.1450e-01,  2.2709e-01, -6.2942e-01,  3.4850e-01,  4.6560e-01,\n         2.9459e-01, -2.3642e-01,  4.6218e-01, -7.3631e-02,  4.3862e-01,\n         1.2286e-01,  9.8999e-01, -1.0245e+00,  2.4983e-01, -1.2601e-01,\n         4.3485e-01,  6.3421e-01,  3.8452e-01,  9.8958e-03, -6.1150e-02,\n        -2.8366e-01, -3.5584e-01, -3.4806e-01,  4.6458e-02,  1.0344e-01,\n        -1.7640e-01,  2.6008e-01,  3.0842e-01, -5.9029e-01,  6.2168e-02,\n         8.0234e-02, -2.1006e-01, -1.3377e+00,  4.7618e-01, -2.3790e-01,\n         5.6921e-01, -1.8896e-01,  8.6591e-02,  1.3231e-02,  1.2710e-01,\n        -5.3515e-01,  3.2699e-01, -2.2347e-01,  2.8715e-01, -1.1292e+00,\n         7.7704e-02,  5.1702e-01,  2.5250e-02,  8.0246e-01, -2.2748e-01,\n         4.8657e-01,  4.7917e-01,  5.0834e-01, -1.8833e-01,  5.0228e-01,\n        -3.7779e-01, -3.9931e-01,  2.4244e-01,  2.1779e-01, -1.0248e-01,\n         4.3215e-01,  1.9822e-01, -4.4591e-01,  5.6154e-01,  3.0105e-01,\n        -4.6189e-01, -8.0389e-01,  9.8432e-01, -3.1944e-01,  9.4833e-02,\n         1.1400e-01, -1.5258e-01,  8.6682e-02, -5.9506e-03,  1.0061e+00,\n         3.5015e-01, -5.4344e-01, -1.4929e-02,  2.9061e-01,  7.7716e-01,\n         5.7593e-02,  4.1433e-01,  2.0678e-01,  1.1295e-01, -3.3525e-01,\n        -6.4733e-01, -2.0853e-01, -6.8152e-01, -2.3764e-01, -7.2244e-03,\n         5.3895e-02, -1.7540e-02, -3.5193e+00, -2.7689e-01, -1.4060e-01,\n         2.2860e-01, -2.3910e-01,  1.4758e-01,  4.6928e-01, -4.1897e-01,\n        -8.1610e-01,  6.8833e-01, -5.3819e-01, -5.4749e-02, -1.4693e-01,\n         1.5520e-01,  3.4751e-01, -1.0811e-02, -1.1496e-01, -3.7802e-01,\n        -5.4832e-02, -1.7603e-01, -1.5183e-01, -3.5338e-03, -1.5314e-02,\n        -1.0327e-01, -4.9390e-01, -9.5211e-03,  2.2363e-01, -8.6061e-02,\n        -1.6430e+00,  4.8663e-01,  2.2926e-01, -1.5008e-01,  4.6846e-03,\n         1.8621e-01,  5.8974e-01, -2.3210e-01, -3.8068e-02,  5.2106e-02,\n        -2.1625e-01,  1.3113e-01, -1.6528e-01, -3.0899e-01, -8.6106e-02,\n         1.1730e-01, -2.2622e-01, -3.6722e-01, -1.5751e-01, -3.6578e-02,\n        -3.0102e-01, -4.9017e-02, -4.6044e-01,  4.7928e-01,  3.5405e-02,\n         9.5526e-02, -1.9290e-01,  3.5486e-01,  3.5565e-01, -4.3436e-01,\n        -3.7214e-01,  3.7490e-01, -1.4289e-01,  1.4892e-01,  4.4548e-01,\n        -6.1742e-02,  3.3417e-01,  1.5622e+00, -1.6550e-01, -9.5622e-02,\n        -3.1609e-01,  3.5710e-01,  1.5547e-01,  3.7913e-01, -4.5316e-01,\n        -3.0411e-01,  6.3645e-01,  4.6493e-01, -2.7021e-01,  2.8007e-01,\n         3.5020e-01,  4.3037e-01, -2.0467e-01, -1.7361e-01,  5.0707e-02,\n         5.2277e-01, -1.6470e-01,  2.9059e-01,  9.7539e-02, -8.1670e-02,\n         3.0347e-01,  3.0409e-01, -1.9271e-01, -3.8301e-01,  5.5685e-01,\n        -2.9989e-01,  7.5335e-01, -1.9442e-01, -8.1730e-01, -5.7642e-02,\n         4.5157e-01, -1.0122e+00,  3.4106e-02,  3.7177e-01,  4.8461e-01,\n         1.0395e+00,  3.5976e-01,  1.9491e-01, -1.8765e-01,  9.0858e-02,\n        -1.2970e-01, -6.9582e-02, -3.3006e-01,  1.2637e-01, -1.4938e-01,\n         1.7854e-01, -3.3438e-02,  2.9249e-01, -6.0153e-02, -3.9808e-01,\n        -4.7156e-02,  1.6853e-01, -2.4003e-02, -9.1483e-02,  3.4247e-01,\n         2.2795e-01,  3.3932e-01, -3.3874e-01, -5.3320e-02, -1.2861e-02,\n        -1.2411e-02,  3.7387e-02,  5.8254e-02, -2.5397e-01,  5.2348e-01,\n         8.6658e-01, -3.5760e-01,  1.3084e-01, -1.1010e-01,  5.1624e-01,\n         6.0349e-01, -4.8093e-01,  1.6971e-01,  1.2630e+00, -2.6303e-01,\n         1.8936e-01,  2.1825e-01,  2.9491e-02, -3.4005e-01, -4.3871e+01,\n         4.7595e-02, -1.4228e-01, -1.0846e-01, -1.5160e-01,  1.0329e-01,\n         3.7053e-01, -1.2320e-02,  3.1999e-01,  5.6906e-02,  3.0835e-01,\n         2.0784e-01, -3.3139e-01, -4.5700e-01, -1.5465e-01,  1.6962e-01,\n        -3.5235e-01, -7.5174e-03,  4.5752e-01,  4.0825e-01, -1.1673e-01,\n        -1.0488e-02,  2.5212e-02, -1.6757e-01,  2.3002e-01, -1.8673e-02,\n        -1.7697e-01, -2.1341e-01, -6.6391e-01, -1.8274e-01,  7.0124e-01,\n         2.5572e-01,  1.5160e-01, -2.0538e-01,  1.8113e-01, -4.6497e-02,\n        -2.5627e-01, -4.6529e-01,  1.9979e-01, -1.2916e-01, -3.4473e-01,\n        -4.8907e-01, -3.6988e-01,  1.0921e-01, -1.2943e-01, -1.2346e-01,\n         8.8096e-02,  1.2546e+00,  6.3094e+00, -2.5674e-01, -4.3520e-01,\n        -2.3859e+00,  4.8746e-01, -3.9125e-02, -4.1557e-02, -2.7922e-01,\n         8.7475e-02,  2.1376e-01, -6.5235e-02, -1.2277e+00, -2.0121e+01,\n         4.7794e-01,  3.3857e-01,  1.3460e-01,  4.3976e-01,  1.7539e-01,\n         2.3180e-01, -3.4298e-01,  2.6690e-01, -3.0966e-01, -8.0459e-01,\n         1.0486e-01,  2.3068e-01, -2.7034e-01, -7.2113e-02,  1.2232e+00,\n        -3.3541e-02,  1.2416e-01, -5.4055e-02,  3.2458e-01, -2.6819e-01,\n        -2.7736e-01, -1.0285e-01, -3.2138e-01,  4.5720e-01,  1.7563e-01,\n        -5.7128e-02,  1.5178e-01, -4.0476e-01,  5.8006e-02,  3.9195e-02,\n        -2.5981e-01,  2.0811e-01, -2.8853e-01,  6.6633e+00, -5.7252e-01,\n        -5.5131e-02,  7.3943e-02,  3.7546e-01,  5.8285e-02, -6.3121e-01,\n        -5.0900e-01, -5.1948e-02, -1.1226e-01, -1.6612e-01, -1.6518e-01,\n         4.8815e-01,  1.6613e-01, -4.5851e-01, -5.6316e-01, -3.2561e-02,\n        -1.4305e-01, -2.9152e-01, -6.2530e-01, -1.1286e-01,  6.0920e-03,\n         7.0946e+01,  4.8999e-01,  1.3975e-01, -1.2525e-01, -1.5065e-01,\n         1.6868e-01, -2.7682e-02, -4.1910e-01,  2.6702e-01, -1.3076e+00,\n         4.4607e-01,  1.2542e-01, -2.8018e+00,  1.4158e-01, -5.2851e-01,\n        -3.3754e-01,  1.9284e-02,  1.0982e+00,  6.1203e-02,  2.5273e-01,\n        -6.5044e-01, -1.6463e-01, -3.6856e-01,  7.3381e-02,  2.8394e-01,\n         7.1713e-01, -4.5587e-01, -3.6499e-01, -3.1927e-01,  2.5299e-01,\n         3.1554e-01, -3.9655e-01, -1.6431e-01, -3.2882e-01,  4.8321e-01,\n         2.6438e-02,  3.2431e-01, -7.3670e-01,  3.7471e-01,  2.6125e-01,\n         1.1955e-01, -2.1661e-01,  4.1328e-01,  1.6487e-01,  4.8600e-02,\n        -1.4378e-02, -7.9637e-02, -4.6863e-01, -4.1781e-01,  1.7027e+00,\n        -8.9309e-01,  1.2432e+00,  2.1844e-01,  5.7696e-02,  1.4689e-01,\n         1.5076e-01,  5.9482e-02, -6.2378e-01, -2.9110e-01, -1.6801e-01,\n        -3.6049e-01, -3.8028e-02, -2.2511e-01, -5.7139e-01, -4.8377e-01,\n        -4.3101e-02,  1.8708e+02, -2.1507e-01,  1.9170e-01, -3.0552e-02,\n         2.2827e-01,  1.0583e-01, -7.0139e-02, -2.7798e+00,  1.4771e-01,\n         8.5176e-02, -2.1687e-01,  3.3596e-01,  5.2070e-01,  1.1699e-01,\n         9.5625e-02,  7.2405e-02, -7.4354e-01, -4.1796e-01, -3.1036e-01,\n         1.9051e-01,  1.3422e-01,  1.3123e-02,  6.9384e-02,  4.9266e-01,\n        -3.0280e-01,  4.1873e-01,  3.8501e-01,  5.0008e-02, -4.1961e-01,\n        -9.2081e-01, -8.8505e-01, -4.4598e-01,  3.2327e-01,  3.3958e-01,\n         2.7451e-01,  1.5717e-02, -1.3682e-01, -1.1711e-01,  8.5470e-01,\n         2.0400e-01, -3.2440e-03, -6.6013e-01, -9.5547e-01,  1.1471e-01,\n        -2.7788e-01, -2.0668e-01,  2.4634e-01,  6.9303e-01, -4.9175e-01,\n         5.9871e-01,  2.5664e-01, -3.5525e-02, -6.6084e-01,  3.5962e-03,\n         7.7517e-01,  3.3645e-01,  4.1101e-01,  6.3882e-01, -1.1079e+00,\n         3.5268e-01, -1.6977e-01, -3.6987e-02,  2.5442e-01,  3.5130e-01,\n        -3.1887e-02, -4.1854e-01,  1.6195e-01, -1.2116e-01,  3.4556e-01,\n        -3.1018e-01, -1.4006e-01, -2.2971e-02, -2.4656e-01, -1.3791e-02,\n        -7.8256e-02,  1.3936e-01,  2.5287e-01,  1.2679e-01,  1.0444e-02,\n        -7.2022e-01,  6.0788e-02,  1.3312e-01, -5.9214e-01, -2.5595e-02,\n        -1.9300e-01,  2.0226e-01,  8.7149e-02, -2.8428e-01, -7.0516e-02,\n         2.0947e-01, -2.4657e-01, -2.4485e-01, -9.9435e-02,  3.1029e-01,\n        -3.1992e-02, -6.6761e-02, -6.7534e-01, -8.6753e-01, -6.0732e-02,\n         1.5726e-01,  7.2841e-02, -1.3594e-01,  2.1770e-01, -1.9269e-01,\n         7.0538e-02,  2.4697e-01, -2.1211e-01,  3.9387e-01, -1.1869e-01,\n         3.3987e-01, -2.5016e-01,  3.6958e-02,  1.6831e+00,  1.3615e-02,\n        -1.7321e-01,  5.6813e-01,  6.5152e-01, -1.0398e-01,  3.8231e-01,\n         3.3899e-01,  8.4053e-01,  1.7321e-01,  2.9557e-01,  4.3555e-01,\n        -3.8328e-01,  7.0625e-01,  1.4007e-01,  5.9916e-01,  3.2180e-01,\n         2.8273e-01,  5.9825e-02,  9.4940e-01, -4.5199e-02,  2.8532e-01,\n        -7.0141e-02,  5.2700e-02, -1.2425e-01, -4.9037e-02, -3.8386e-01,\n        -6.8675e-01,  5.6606e-02,  1.1794e-01, -4.0015e-01,  1.5555e-01,\n         4.9732e-01, -2.5473e-02,  6.1942e-01, -4.3914e-01,  3.6841e-01,\n        -1.0106e+00,  5.7044e-01,  6.3400e-01,  1.8109e-01, -1.2689e+00,\n         3.0568e-01, -2.4669e-01, -4.7047e-01, -6.9111e-01, -1.8980e-01,\n         9.3604e-01, -2.0410e-01, -1.1872e-01, -2.7357e-02,  2.3875e-01,\n         3.1092e-01,  1.1390e-02, -2.4784e-01, -7.8412e-03, -6.9789e-01,\n         1.5111e-01, -2.7125e-01, -2.5387e-01, -1.8569e-01,  5.4281e-01,\n        -1.2238e-01,  5.8334e-01, -1.0270e-01, -6.6581e-01,  5.0467e-02,\n         2.2914e-01, -6.2707e-01,  3.1402e-01, -2.5495e-01,  2.1849e-01,\n        -8.2420e-01,  1.0366e-01, -6.9238e-02, -1.6138e-01,  2.4286e-02,\n         8.9909e-02, -2.2955e-02,  1.1647e-01,  3.7806e-01,  3.2999e-01,\n         9.7268e-01,  2.0536e-01,  3.2675e-01,  1.2438e-01,  9.5249e-02,\n         2.0198e-01, -1.1161e-01, -1.8637e-01, -5.8571e-02, -4.2029e-01,\n        -7.9599e-02,  1.5202e-01,  2.0047e-01, -1.0811e+00, -6.1192e-01,\n        -1.4036e-01,  5.7603e-01, -1.3407e-01, -1.2577e-01, -3.3293e-01,\n        -1.4304e-01, -5.7476e-01, -3.0210e-01, -1.0654e-01,  1.8689e-01,\n        -1.1735e-01,  2.6910e-02,  3.3609e-01, -3.8913e-01,  1.3305e-02,\n        -9.7757e-01, -5.0708e-01, -3.9805e-01, -2.5544e-01,  5.2961e-01,\n         7.5593e-01,  2.7601e-01, -1.0440e+00,  4.2858e-01, -3.3402e-01,\n         4.9627e-01, -5.5644e-02,  2.6034e-01, -3.1860e-01,  1.9822e-01,\n        -6.6199e-01,  5.5858e-01, -1.4615e-01, -1.3237e-01, -4.9860e-02,\n         6.2007e-02, -1.5592e-02,  1.9362e-01, -3.9611e-01, -5.7654e-01,\n        -1.5250e+00, -1.2473e-01,  1.1547e-01,  1.7411e-02, -4.1657e-01,\n        -3.4960e-02,  3.0048e-01, -3.1938e-01,  4.4102e-01, -6.5498e-01,\n         3.7197e-01, -1.3987e-01,  1.6034e-01, -6.5139e-01,  3.1342e-01,\n        -2.8109e-01,  1.6483e-01,  1.8485e-01, -7.5067e-01,  1.2059e-01,\n         2.5470e-01, -8.5622e-02,  4.0347e-02])\n\n\nNow we animate through the residual stream.\n\nresidual_stream = np.zeros((13, d_model))\n\nfor layer in range(13):\n    residual_stream_layer = outputs.hidden_states[layer][0, -1, :].numpy()\n    residual_stream[layer] = residual_stream_layer\n    print(f\"Layer {layer}: Residual stream shape {residual_stream_layer.shape}\")\n\nLayer 0: Residual stream shape (768,)\nLayer 1: Residual stream shape (768,)\nLayer 2: Residual stream shape (768,)\nLayer 3: Residual stream shape (768,)\nLayer 4: Residual stream shape (768,)\nLayer 5: Residual stream shape (768,)\nLayer 6: Residual stream shape (768,)\nLayer 7: Residual stream shape (768,)\nLayer 8: Residual stream shape (768,)\nLayer 9: Residual stream shape (768,)\nLayer 10: Residual stream shape (768,)\nLayer 11: Residual stream shape (768,)\nLayer 12: Residual stream shape (768,)\n\n\n\nresidual_stream = rearrange(residual_stream, \"layer (row col) -&gt; layer row col\", row=16)\n\nresidual_stream.shape\n\n(13, 16, 48)\n\n\n\nfrom ipywidgets import interact, interactive, IntSlider, VBox, HBox, Output\nimport matplotlib.pyplot as plt\n\noutput = Output()\n\ndef plot_layer(layer=0):\n    with output:\n        output.clear_output(wait=True)\n        fig, ax = plt.subplots(1, 1, figsize=(15, 5))\n        ax.axis(False)\n        fig.set_facecolor('white')\n        ax.set_facecolor('white')\n\n        cmesh = ax.pcolormesh(residual_stream[layer], edgecolors='white', cmap='viridis', vmin=-3, vmax=3)\n        ax.set_title(f'Layer {layer}', color='black', fontsize=16)\n        plt.show()\n\nslider = IntSlider(min=0, max=residual_stream.shape[0]-1, step=1, value=0, description='Layer:')\nslider.observe(lambda change: plot_layer(change['new']), names='value')\n\n# Initial plot\nplot_layer(0)\n\n# Display with slider below and centered\nfrom ipywidgets import Layout\ndisplay(VBox([output, HBox([slider], layout=Layout(justify_content='center'))],\n             layout=Layout(background_color='white')))"
  },
  {
    "objectID": "blog/posts/residual-stream/residual_stream_animation.html",
    "href": "blog/posts/residual-stream/residual_stream_animation.html",
    "title": "",
    "section": "",
    "text": "import numpy as np\n\n\nd_model = 768\nn_layers = 12\n\nresidual_stream = np.random.randn(n_layers, d_model)\n\nresidual_stream.shape\n\n(12, 768)\n\n\nLet’s use Einops to rearrange this into a nice array to visualize.\n\nfrom einops import rearrange, reduce, repeat\n\nresidual_stream = rearrange(residual_stream, \"layer (row col) -&gt; layer row col\", row=16)\n\nresidual_stream.shape\n\n(12, 16, 48)\n\n\nNow we do the simplest plot of such a tensor.\n\nimport matplotlib.pyplot as plt\n\nplt.imshow(residual_stream[0], cmap='viridis')\nplt.title(\"Residual Stream at Layer 0\")\nplt.show()\n\n\n\n\n\n\n\n\nWe want to make this much prettier for the blog.\n\nfig, ax = plt.subplots(1,1, figsize=(15,5))\nax.axis(False)\nfig.set_facecolor('black')\nax.set_facecolor('black')\n\ncmesh = ax.pcolormesh(residual_stream[0], edgecolors='k', cmap='viridis', vmin=-3, vmax=3)\n\n\n\n\nAnimation of the Residual Stream Across Layers\n\n\n\n\nNow we can think about animating this.\n\nfrom matplotlib.animation import FuncAnimation\n\ndef anim_function(frame_num):\n    cmesh.set_array(residual_stream[frame_num,:,:])\n    return cmesh,\n\nanim = FuncAnimation(fig, anim_function, frames=np.arange(residual_stream.shape[0]), interval=30)\n\nfrom IPython.display import HTML\nHTML(anim.to_jshtml())\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\nNow lets look to do something with actual model activations!\n\nfrom huggingface_hub import login\nlogin()\n\n\nimport torch\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\n\nmodel_name = \"gpt2\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForCausalLM.from_pretrained(model_name)\ntokenizer.pad_token = tokenizer.eos_token\n\n\n\n\nGPT2LMHeadModel LOAD REPORT from: gpt2\nKey                  | Status     |  | \n---------------------+------------+--+-\nh.{0...11}.attn.bias | UNEXPECTED |  | \n\nNotes:\n- UNEXPECTED    :can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n\n\n\ninputs = tokenizer(\n    \"Paris is the capital of\",\n    padding=True,\n    truncation=True,\n    return_tensors=\"pt\"\n)\n\nprint(f\"Tokenized {inputs['input_ids'].shape[0]} sequences with max length {inputs['input_ids'].shape[1]}.\")\n\nTokenized 1 sequences with max length 5.\n\n\n\nwith torch.no_grad():\n    outputs = model(\n        input_ids=inputs[\"input_ids\"],\n        attention_mask=inputs[\"attention_mask\"],\n        output_hidden_states=True,\n    )\n\n\ntype(outputs.hidden_states)\n\ntuple\n\n\n\noutputs.hidden_states[12][0, -1, :]\n\ntensor([ 3.9707e-01,  6.5592e-01, -1.0789e-01, -5.1339e-01,  2.2478e-01,\n        -3.5340e-01,  2.9402e+00,  5.0266e-01, -1.1648e-01, -3.3925e-01,\n        -1.4641e-01,  1.3185e-01,  5.6856e-01, -2.4193e-01,  2.3383e-01,\n        -6.1204e-01, -1.6270e-01,  2.6729e-01,  1.0813e-01, -3.3550e+00,\n         3.8122e-01,  3.1480e-01,  3.6961e-01, -1.1843e-01, -4.1384e-02,\n         2.7716e-01, -6.5405e-01, -6.8845e-01,  1.7058e-01,  2.3255e-01,\n         2.1136e-02, -2.7776e-01,  1.7016e-01,  3.5261e-01,  6.2866e-01,\n        -2.2970e-01,  5.0996e+01, -3.4832e-01, -4.9283e-01,  1.6009e-01,\n        -2.5912e-01, -4.3954e-02, -6.6652e-02,  1.7371e-02, -4.9989e-02,\n         7.7331e-02, -2.0900e-01, -5.2491e-01, -9.1295e-01, -7.5307e-02,\n        -5.9557e-02, -3.5249e-01,  9.1986e-02, -4.4967e-02,  1.7474e-01,\n         1.0622e+00, -3.1931e-02, -2.3144e-01,  1.4521e-01, -4.0620e-01,\n        -5.8457e-01,  1.4042e-02,  1.0694e-01, -1.2151e-01, -1.1069e+00,\n         4.4808e-01, -1.6879e-01,  4.8419e-02, -1.2701e+00,  1.9134e-01,\n        -7.3997e-01, -6.9388e-01,  9.3711e-03, -3.0020e-01, -2.9383e-02,\n         1.1450e-01,  2.2709e-01, -6.2942e-01,  3.4850e-01,  4.6560e-01,\n         2.9459e-01, -2.3642e-01,  4.6218e-01, -7.3631e-02,  4.3862e-01,\n         1.2286e-01,  9.8999e-01, -1.0245e+00,  2.4983e-01, -1.2601e-01,\n         4.3485e-01,  6.3421e-01,  3.8452e-01,  9.8958e-03, -6.1150e-02,\n        -2.8366e-01, -3.5584e-01, -3.4806e-01,  4.6458e-02,  1.0344e-01,\n        -1.7640e-01,  2.6008e-01,  3.0842e-01, -5.9029e-01,  6.2168e-02,\n         8.0234e-02, -2.1006e-01, -1.3377e+00,  4.7618e-01, -2.3790e-01,\n         5.6921e-01, -1.8896e-01,  8.6591e-02,  1.3231e-02,  1.2710e-01,\n        -5.3515e-01,  3.2699e-01, -2.2347e-01,  2.8715e-01, -1.1292e+00,\n         7.7704e-02,  5.1702e-01,  2.5250e-02,  8.0246e-01, -2.2748e-01,\n         4.8657e-01,  4.7917e-01,  5.0834e-01, -1.8833e-01,  5.0228e-01,\n        -3.7779e-01, -3.9931e-01,  2.4244e-01,  2.1779e-01, -1.0248e-01,\n         4.3215e-01,  1.9822e-01, -4.4591e-01,  5.6154e-01,  3.0105e-01,\n        -4.6189e-01, -8.0389e-01,  9.8432e-01, -3.1944e-01,  9.4833e-02,\n         1.1400e-01, -1.5258e-01,  8.6682e-02, -5.9506e-03,  1.0061e+00,\n         3.5015e-01, -5.4344e-01, -1.4929e-02,  2.9061e-01,  7.7716e-01,\n         5.7593e-02,  4.1433e-01,  2.0678e-01,  1.1295e-01, -3.3525e-01,\n        -6.4733e-01, -2.0853e-01, -6.8152e-01, -2.3764e-01, -7.2244e-03,\n         5.3895e-02, -1.7540e-02, -3.5193e+00, -2.7689e-01, -1.4060e-01,\n         2.2860e-01, -2.3910e-01,  1.4758e-01,  4.6928e-01, -4.1897e-01,\n        -8.1610e-01,  6.8833e-01, -5.3819e-01, -5.4749e-02, -1.4693e-01,\n         1.5520e-01,  3.4751e-01, -1.0811e-02, -1.1496e-01, -3.7802e-01,\n        -5.4832e-02, -1.7603e-01, -1.5183e-01, -3.5338e-03, -1.5314e-02,\n        -1.0327e-01, -4.9390e-01, -9.5211e-03,  2.2363e-01, -8.6061e-02,\n        -1.6430e+00,  4.8663e-01,  2.2926e-01, -1.5008e-01,  4.6846e-03,\n         1.8621e-01,  5.8974e-01, -2.3210e-01, -3.8068e-02,  5.2106e-02,\n        -2.1625e-01,  1.3113e-01, -1.6528e-01, -3.0899e-01, -8.6106e-02,\n         1.1730e-01, -2.2622e-01, -3.6722e-01, -1.5751e-01, -3.6578e-02,\n        -3.0102e-01, -4.9017e-02, -4.6044e-01,  4.7928e-01,  3.5405e-02,\n         9.5526e-02, -1.9290e-01,  3.5486e-01,  3.5565e-01, -4.3436e-01,\n        -3.7214e-01,  3.7490e-01, -1.4289e-01,  1.4892e-01,  4.4548e-01,\n        -6.1742e-02,  3.3417e-01,  1.5622e+00, -1.6550e-01, -9.5622e-02,\n        -3.1609e-01,  3.5710e-01,  1.5547e-01,  3.7913e-01, -4.5316e-01,\n        -3.0411e-01,  6.3645e-01,  4.6493e-01, -2.7021e-01,  2.8007e-01,\n         3.5020e-01,  4.3037e-01, -2.0467e-01, -1.7361e-01,  5.0707e-02,\n         5.2277e-01, -1.6470e-01,  2.9059e-01,  9.7539e-02, -8.1670e-02,\n         3.0347e-01,  3.0409e-01, -1.9271e-01, -3.8301e-01,  5.5685e-01,\n        -2.9989e-01,  7.5335e-01, -1.9442e-01, -8.1730e-01, -5.7642e-02,\n         4.5157e-01, -1.0122e+00,  3.4106e-02,  3.7177e-01,  4.8461e-01,\n         1.0395e+00,  3.5976e-01,  1.9491e-01, -1.8765e-01,  9.0858e-02,\n        -1.2970e-01, -6.9582e-02, -3.3006e-01,  1.2637e-01, -1.4938e-01,\n         1.7854e-01, -3.3438e-02,  2.9249e-01, -6.0153e-02, -3.9808e-01,\n        -4.7156e-02,  1.6853e-01, -2.4003e-02, -9.1483e-02,  3.4247e-01,\n         2.2795e-01,  3.3932e-01, -3.3874e-01, -5.3320e-02, -1.2861e-02,\n        -1.2411e-02,  3.7387e-02,  5.8254e-02, -2.5397e-01,  5.2348e-01,\n         8.6658e-01, -3.5760e-01,  1.3084e-01, -1.1010e-01,  5.1624e-01,\n         6.0349e-01, -4.8093e-01,  1.6971e-01,  1.2630e+00, -2.6303e-01,\n         1.8936e-01,  2.1825e-01,  2.9491e-02, -3.4005e-01, -4.3871e+01,\n         4.7595e-02, -1.4228e-01, -1.0846e-01, -1.5160e-01,  1.0329e-01,\n         3.7053e-01, -1.2320e-02,  3.1999e-01,  5.6906e-02,  3.0835e-01,\n         2.0784e-01, -3.3139e-01, -4.5700e-01, -1.5465e-01,  1.6962e-01,\n        -3.5235e-01, -7.5174e-03,  4.5752e-01,  4.0825e-01, -1.1673e-01,\n        -1.0488e-02,  2.5212e-02, -1.6757e-01,  2.3002e-01, -1.8673e-02,\n        -1.7697e-01, -2.1341e-01, -6.6391e-01, -1.8274e-01,  7.0124e-01,\n         2.5572e-01,  1.5160e-01, -2.0538e-01,  1.8113e-01, -4.6497e-02,\n        -2.5627e-01, -4.6529e-01,  1.9979e-01, -1.2916e-01, -3.4473e-01,\n        -4.8907e-01, -3.6988e-01,  1.0921e-01, -1.2943e-01, -1.2346e-01,\n         8.8096e-02,  1.2546e+00,  6.3094e+00, -2.5674e-01, -4.3520e-01,\n        -2.3859e+00,  4.8746e-01, -3.9125e-02, -4.1557e-02, -2.7922e-01,\n         8.7475e-02,  2.1376e-01, -6.5235e-02, -1.2277e+00, -2.0121e+01,\n         4.7794e-01,  3.3857e-01,  1.3460e-01,  4.3976e-01,  1.7539e-01,\n         2.3180e-01, -3.4298e-01,  2.6690e-01, -3.0966e-01, -8.0459e-01,\n         1.0486e-01,  2.3068e-01, -2.7034e-01, -7.2113e-02,  1.2232e+00,\n        -3.3541e-02,  1.2416e-01, -5.4055e-02,  3.2458e-01, -2.6819e-01,\n        -2.7736e-01, -1.0285e-01, -3.2138e-01,  4.5720e-01,  1.7563e-01,\n        -5.7128e-02,  1.5178e-01, -4.0476e-01,  5.8006e-02,  3.9195e-02,\n        -2.5981e-01,  2.0811e-01, -2.8853e-01,  6.6633e+00, -5.7252e-01,\n        -5.5131e-02,  7.3943e-02,  3.7546e-01,  5.8285e-02, -6.3121e-01,\n        -5.0900e-01, -5.1948e-02, -1.1226e-01, -1.6612e-01, -1.6518e-01,\n         4.8815e-01,  1.6613e-01, -4.5851e-01, -5.6316e-01, -3.2561e-02,\n        -1.4305e-01, -2.9152e-01, -6.2530e-01, -1.1286e-01,  6.0920e-03,\n         7.0946e+01,  4.8999e-01,  1.3975e-01, -1.2525e-01, -1.5065e-01,\n         1.6868e-01, -2.7682e-02, -4.1910e-01,  2.6702e-01, -1.3076e+00,\n         4.4607e-01,  1.2542e-01, -2.8018e+00,  1.4158e-01, -5.2851e-01,\n        -3.3754e-01,  1.9284e-02,  1.0982e+00,  6.1203e-02,  2.5273e-01,\n        -6.5044e-01, -1.6463e-01, -3.6856e-01,  7.3381e-02,  2.8394e-01,\n         7.1713e-01, -4.5587e-01, -3.6499e-01, -3.1927e-01,  2.5299e-01,\n         3.1554e-01, -3.9655e-01, -1.6431e-01, -3.2882e-01,  4.8321e-01,\n         2.6438e-02,  3.2431e-01, -7.3670e-01,  3.7471e-01,  2.6125e-01,\n         1.1955e-01, -2.1661e-01,  4.1328e-01,  1.6487e-01,  4.8600e-02,\n        -1.4378e-02, -7.9637e-02, -4.6863e-01, -4.1781e-01,  1.7027e+00,\n        -8.9309e-01,  1.2432e+00,  2.1844e-01,  5.7696e-02,  1.4689e-01,\n         1.5076e-01,  5.9482e-02, -6.2378e-01, -2.9110e-01, -1.6801e-01,\n        -3.6049e-01, -3.8028e-02, -2.2511e-01, -5.7139e-01, -4.8377e-01,\n        -4.3101e-02,  1.8708e+02, -2.1507e-01,  1.9170e-01, -3.0552e-02,\n         2.2827e-01,  1.0583e-01, -7.0139e-02, -2.7798e+00,  1.4771e-01,\n         8.5176e-02, -2.1687e-01,  3.3596e-01,  5.2070e-01,  1.1699e-01,\n         9.5625e-02,  7.2405e-02, -7.4354e-01, -4.1796e-01, -3.1036e-01,\n         1.9051e-01,  1.3422e-01,  1.3123e-02,  6.9384e-02,  4.9266e-01,\n        -3.0280e-01,  4.1873e-01,  3.8501e-01,  5.0008e-02, -4.1961e-01,\n        -9.2081e-01, -8.8505e-01, -4.4598e-01,  3.2327e-01,  3.3958e-01,\n         2.7451e-01,  1.5717e-02, -1.3682e-01, -1.1711e-01,  8.5470e-01,\n         2.0400e-01, -3.2440e-03, -6.6013e-01, -9.5547e-01,  1.1471e-01,\n        -2.7788e-01, -2.0668e-01,  2.4634e-01,  6.9303e-01, -4.9175e-01,\n         5.9871e-01,  2.5664e-01, -3.5525e-02, -6.6084e-01,  3.5962e-03,\n         7.7517e-01,  3.3645e-01,  4.1101e-01,  6.3882e-01, -1.1079e+00,\n         3.5268e-01, -1.6977e-01, -3.6987e-02,  2.5442e-01,  3.5130e-01,\n        -3.1887e-02, -4.1854e-01,  1.6195e-01, -1.2116e-01,  3.4556e-01,\n        -3.1018e-01, -1.4006e-01, -2.2971e-02, -2.4656e-01, -1.3791e-02,\n        -7.8256e-02,  1.3936e-01,  2.5287e-01,  1.2679e-01,  1.0444e-02,\n        -7.2022e-01,  6.0788e-02,  1.3312e-01, -5.9214e-01, -2.5595e-02,\n        -1.9300e-01,  2.0226e-01,  8.7149e-02, -2.8428e-01, -7.0516e-02,\n         2.0947e-01, -2.4657e-01, -2.4485e-01, -9.9435e-02,  3.1029e-01,\n        -3.1992e-02, -6.6761e-02, -6.7534e-01, -8.6753e-01, -6.0732e-02,\n         1.5726e-01,  7.2841e-02, -1.3594e-01,  2.1770e-01, -1.9269e-01,\n         7.0538e-02,  2.4697e-01, -2.1211e-01,  3.9387e-01, -1.1869e-01,\n         3.3987e-01, -2.5016e-01,  3.6958e-02,  1.6831e+00,  1.3615e-02,\n        -1.7321e-01,  5.6813e-01,  6.5152e-01, -1.0398e-01,  3.8231e-01,\n         3.3899e-01,  8.4053e-01,  1.7321e-01,  2.9557e-01,  4.3555e-01,\n        -3.8328e-01,  7.0625e-01,  1.4007e-01,  5.9916e-01,  3.2180e-01,\n         2.8273e-01,  5.9825e-02,  9.4940e-01, -4.5199e-02,  2.8532e-01,\n        -7.0141e-02,  5.2700e-02, -1.2425e-01, -4.9037e-02, -3.8386e-01,\n        -6.8675e-01,  5.6606e-02,  1.1794e-01, -4.0015e-01,  1.5555e-01,\n         4.9732e-01, -2.5473e-02,  6.1942e-01, -4.3914e-01,  3.6841e-01,\n        -1.0106e+00,  5.7044e-01,  6.3400e-01,  1.8109e-01, -1.2689e+00,\n         3.0568e-01, -2.4669e-01, -4.7047e-01, -6.9111e-01, -1.8980e-01,\n         9.3604e-01, -2.0410e-01, -1.1872e-01, -2.7357e-02,  2.3875e-01,\n         3.1092e-01,  1.1390e-02, -2.4784e-01, -7.8412e-03, -6.9789e-01,\n         1.5111e-01, -2.7125e-01, -2.5387e-01, -1.8569e-01,  5.4281e-01,\n        -1.2238e-01,  5.8334e-01, -1.0270e-01, -6.6581e-01,  5.0467e-02,\n         2.2914e-01, -6.2707e-01,  3.1402e-01, -2.5495e-01,  2.1849e-01,\n        -8.2420e-01,  1.0366e-01, -6.9238e-02, -1.6138e-01,  2.4286e-02,\n         8.9909e-02, -2.2955e-02,  1.1647e-01,  3.7806e-01,  3.2999e-01,\n         9.7268e-01,  2.0536e-01,  3.2675e-01,  1.2438e-01,  9.5249e-02,\n         2.0198e-01, -1.1161e-01, -1.8637e-01, -5.8571e-02, -4.2029e-01,\n        -7.9599e-02,  1.5202e-01,  2.0047e-01, -1.0811e+00, -6.1192e-01,\n        -1.4036e-01,  5.7603e-01, -1.3407e-01, -1.2577e-01, -3.3293e-01,\n        -1.4304e-01, -5.7476e-01, -3.0210e-01, -1.0654e-01,  1.8689e-01,\n        -1.1735e-01,  2.6910e-02,  3.3609e-01, -3.8913e-01,  1.3305e-02,\n        -9.7757e-01, -5.0708e-01, -3.9805e-01, -2.5544e-01,  5.2961e-01,\n         7.5593e-01,  2.7601e-01, -1.0440e+00,  4.2858e-01, -3.3402e-01,\n         4.9627e-01, -5.5644e-02,  2.6034e-01, -3.1860e-01,  1.9822e-01,\n        -6.6199e-01,  5.5858e-01, -1.4615e-01, -1.3237e-01, -4.9860e-02,\n         6.2007e-02, -1.5592e-02,  1.9362e-01, -3.9611e-01, -5.7654e-01,\n        -1.5250e+00, -1.2473e-01,  1.1547e-01,  1.7411e-02, -4.1657e-01,\n        -3.4960e-02,  3.0048e-01, -3.1938e-01,  4.4102e-01, -6.5498e-01,\n         3.7197e-01, -1.3987e-01,  1.6034e-01, -6.5139e-01,  3.1342e-01,\n        -2.8109e-01,  1.6483e-01,  1.8485e-01, -7.5067e-01,  1.2059e-01,\n         2.5470e-01, -8.5622e-02,  4.0347e-02])\n\n\nNow we animate through the residual stream.\n\nresidual_stream = np.zeros((13, d_model))\n\nfor layer in range(13):\n    residual_stream_layer = outputs.hidden_states[layer][0, -1, :].numpy()\n    residual_stream[layer] = residual_stream_layer\n    print(f\"Layer {layer}: Residual stream shape {residual_stream_layer.shape}\")\n\nLayer 0: Residual stream shape (768,)\nLayer 1: Residual stream shape (768,)\nLayer 2: Residual stream shape (768,)\nLayer 3: Residual stream shape (768,)\nLayer 4: Residual stream shape (768,)\nLayer 5: Residual stream shape (768,)\nLayer 6: Residual stream shape (768,)\nLayer 7: Residual stream shape (768,)\nLayer 8: Residual stream shape (768,)\nLayer 9: Residual stream shape (768,)\nLayer 10: Residual stream shape (768,)\nLayer 11: Residual stream shape (768,)\nLayer 12: Residual stream shape (768,)\n\n\n\nresidual_stream = rearrange(residual_stream, \"layer (row col) -&gt; layer row col\", row=16)\n\nresidual_stream.shape\n\n(13, 16, 48)\n\n\n\nfrom ipywidgets import interact, interactive, IntSlider, VBox, HBox, Output\nimport matplotlib.pyplot as plt\n\noutput = Output()\n\ndef plot_layer(layer=0):\n    with output:\n        output.clear_output(wait=True)\n        fig, ax = plt.subplots(1, 1, figsize=(15, 5))\n        ax.axis(False)\n        fig.set_facecolor('black')\n        ax.set_facecolor('black')\n\n        cmesh = ax.pcolormesh(residual_stream[layer], edgecolors='black', cmap='viridis', vmin=-3, vmax=3)\n        ax.set_title(f'Layer {layer}', color='white', fontsize=16)\n        plt.show()\n\nslider = IntSlider(min=0, max=residual_stream.shape[0]-1, step=1, value=0, description='Layer:')\nslider.observe(lambda change: plot_layer(change['new']), names='value')\n\n# Initial plot\nplot_layer(0)\n\n# Display with slider below and centered\nfrom ipywidgets import Layout\ndisplay(VBox([output, HBox([slider], layout=Layout(justify_content='center'))],\n             layout=Layout(background_color='white')))"
  },
  {
    "objectID": "blog/posts/residual-stream/logit-lens.html",
    "href": "blog/posts/residual-stream/logit-lens.html",
    "title": "",
    "section": "",
    "text": "from huggingface_hub import login\nlogin()\n\n\nimport matplotlib.pyplot as plt\nfrom matplotlib.colors import LogNorm\nimport numpy as np\nimport torch\nimport torch.nn as nn\nfrom tqdm import tqdm\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\n\n\ndevice = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\nmodel_name = \"microsoft/phi-3-mini-4k-instruct\"\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_name).to(device)\n\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n\nmodel\n\n\n\n\nPhi3ForCausalLM(\n  (model): Phi3Model(\n    (embed_tokens): Embedding(32064, 3072, padding_idx=32000)\n    (layers): ModuleList(\n      (0-31): 32 x Phi3DecoderLayer(\n        (self_attn): Phi3Attention(\n          (o_proj): Linear(in_features=3072, out_features=3072, bias=False)\n          (qkv_proj): Linear(in_features=3072, out_features=9216, bias=False)\n        )\n        (mlp): Phi3MLP(\n          (gate_up_proj): Linear(in_features=3072, out_features=16384, bias=False)\n          (down_proj): Linear(in_features=8192, out_features=3072, bias=False)\n          (activation_fn): SiLUActivation()\n        )\n        (input_layernorm): Phi3RMSNorm((3072,), eps=1e-05)\n        (post_attention_layernorm): Phi3RMSNorm((3072,), eps=1e-05)\n        (resid_attn_dropout): Dropout(p=0.0, inplace=False)\n        (resid_mlp_dropout): Dropout(p=0.0, inplace=False)\n      )\n    )\n    (norm): Phi3RMSNorm((3072,), eps=1e-05)\n    (rotary_emb): Phi3RotaryEmbedding()\n  )\n  (lm_head): Linear(in_features=3072, out_features=32064, bias=False)\n)\n\n\n\ntext = \"1:sunshine, 2:apple, 3:koala, 2:apple, 1:sunshine, 3:koala, 1:\"\ntext_tokenized = tokenizer.encode(text, return_tensors=\"pt\").to(device)\noutput = model.generate(text_tokenized, num_beams=4, max_new_tokens=3, do_sample=True)\ntext_decoded = tokenizer.decode(output[0])\nprint(text_decoded)\n\n1:sunshine, 2:apple, 3:koala, 2:apple, 1:sunshine, 3:koala, 1:sunshine\n\n\n\ndef decode_token_with_logit_lens(\n    model,\n    device,\n    tokenizer,\n    input,\n    tokens_to_gen=None\n):\n    inputs = tokenizer(input, return_tensors=\"pt\").to(device)\n\n    text = tokenizer.decode(inputs['input_ids'][0])\n\n    if tokens_to_gen != None:\n        output = model.generate(\n            inputs['input_ids'],\n            do_sample=True,\n            top_p=0.95,\n            temperature=0.001,\n            tok_k=0,\n            max_new_tokens=tokens_to_gen\n        )\n        new_token = tokenizer.decode(output[0][-tokens_to_gen:])\n        text += new_token\n        inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n    text_tokens = [tokenizer.decode(id) for id in inputs['input_ids'][0]]\n\nclassifier_head = model.lm_head\n\nhidden_states = model(**inputs, output_hidden_states=True).hidden_states\n\ndecoded_intermediate_tokens = {}\ndecoded_intermediate_logits = {}\n\nwith torch.no_grad():\n    for layer_id in range(len(hidden_states)):\n        hidden_state = hidden_states[layer_id]\n        decoded_value = classifier_head(hidden_state)\n        decoded_values = torch.nn.functional.softmax(decoded_value, dim=-1)\n        argmax = torch.argmax(decoded_values, dim=-1)\n        decoded_token = [tokenizer.decode([id]) for id in argmax]\n        decoded_logit = [decoded_values[0, it, argmax[0, it]].item() for it in range(len(argmax[0]))]\n        decoded_intermediate_tokens[layer_id] = decoded_token\n        decoded_intermediate_logits[layer_id] = decoded_logit\n\ntokens = list(decoded_intermediate_tokens.values())\nlogits = list(decoded_intermediate_logits.values())\nreturn {'text_tokens': text_tokens,\n        'decoded_tokens': tokens,\n        'decoded_logits': logits}"
  },
  {
    "objectID": "notebooks/Branching model tutorial.html",
    "href": "notebooks/Branching model tutorial.html",
    "title": "Recreating branching model animations",
    "section": "",
    "text": "Artem Kirsanov, August 2023\n\nimport numpy as np\nfrom copy import deepcopy\nimport itertools\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom numpy import radians as rad\nfrom matplotlib.animation import FuncAnimation\nfrom scipy.ndimage import convolve,convolve1d\nimport cmasher\nimport seaborn as sns\n\n\nMatplotlib\n\nNUM_LAYERS = 20\nNEURONS_PER_LAYER = 10\n\n\ndef network_init():\n    return np.zeros((NUM_LAYERS, NEURONS_PER_LAYER),dtype=bool)\n\n\ndef network_advance(old_network, sigma,spont_prob):\n    '''Advance one time step'''\n    network = deepcopy(old_network)\n    spont = np.random.rand(*network.shape)\n    network[spont&lt;spont_prob] = 1 # Random spontaneous activity\n    for layer_num in range(NUM_LAYERS-1, 0, -1):\n        # Randomly propagate, starting from the last layer\n        propagation_mask = np.random.rand(NEURONS_PER_LAYER) &lt; sigma*np.sum(network[layer_num-1,:])/NEURONS_PER_LAYER\n        network[layer_num] = propagation_mask\n        network[layer_num-1] = np.zeros(NEURONS_PER_LAYER)\n    return network\n\n\ndef run_simulation(network, n_steps, sigma=1, spont_prob=0.01):\n    '''Run simulation with stochastic activity for n_steps'''\n    network_states = np.zeros((n_steps, NUM_LAYERS, NEURONS_PER_LAYER))\n    network_states[0,:,:] = network\n\n    for step in range(1,n_steps):\n        network_states[step, :,:] = network_advance(network_states[step-1, :,:], sigma,spont_prob)\n    return network_states\n\n\nnetwork = network_init()\nevolution = run_simulation(network, 50, sigma=1, spont_prob=0.01)\n\n\nfig, ax = plt.subplots(1,1,figsize=(10,5),dpi=200)\nax.axis(False)\nfig.set_facecolor(\"white\")\nax.set_facecolor(\"white\")\n\ncmesh = ax.pcolormesh(evolution[0,:,:].T, edgecolors='white', vmin=0, vmax=1,linewidth=2, cmap=plt.cm.coolwarm)\n\ndef anim_function(frame_num):\n    cmesh.set_array(evolution[frame_num,:,:].T)\n    return cmesh,\n\nanim = FuncAnimation(fig, anim_function, frames=np.arange(evolution.shape[0]), interval=30)\nanim.save(\"Network evolution raw fast.mp4\")\n\n[01/29/26 13:38:31] INFO     Animation.save using &lt;class 'matplotlib.animation.FFMpegWriter'&gt;     animation.py:1076\n\n\n\n                    INFO     MovieWriter._run: running command: ffmpeg -f rawvideo -vcodec         animation.py:319\n                             rawvideo -s 2000x1000 -pix_fmt rgba -framerate 33.333333333333336                     \n                             -loglevel error -i pipe: -vcodec h264 -pix_fmt yuv420p -y 'Network                    \n                             evolution raw fast.mp4'                                                               \n\n\n\n\n\n\n\n\n\n\n\n# --- Running the model\nnetwork = network_init()\nevolution = run_simulation(network, 500, sigma=1, spont_prob=0.01)\n\n# --- Smoothing activity\ndef smooth_activity(network_states, time_stretch=3):\n    '''\n        Smooth the activity in time for a more eye-pleasant animation\n    '''\n    def get_symmetric_kernel(slope=-20, npoints=100):\n        t = np.linspace(0,1,npoints)\n        kernel = np.zeros_like(t)\n        t_mask = t&gt;0.5\n        kernel[t_mask]=np.exp(slope*t[t_mask])\n        kernel[(t&lt;=0.5)]=np.exp(slope*t[t_mask])[::-1]\n        return kernel/kernel[t_mask][0]\n\n    kernel = get_symmetric_kernel(-60)\n    smoothed_activity = np.zeros((network_states.shape[0]*time_stretch, network_states.shape[1], network_states.shape[2]))\n    smoothed_activity[::time_stretch, :, :] = network_states\n    smoothed_activity = convolve1d(smoothed_activity, kernel, axis=0,mode=\"constant\",origin=0)\n    return smoothed_activity\n\n\n# --- Animation\nsmoothed_evolution = smooth_activity(evolution)\nfig, ax = plt.subplots(1,1,figsize=(10,5),dpi=200)\nax.axis(False)\nfig.set_facecolor(\"white\")\nax.set_facecolor(\"white\")\n\ncmap = cmasher.get_sub_cmap(sns.color_palette(\"mako\",as_cmap=True),0.2,1)\ncmesh = ax.pcolormesh(smoothed_evolution[0,:,:].T, edgecolors='white', vmin=0, vmax=1,linewidth=2, cmap=cmap)\n\ndef anim_function(frame_num):\n    cmesh.set_array(smoothed_evolution[frame_num,:,:].T)\n    return cmesh,\n\nanim = FuncAnimation(fig, anim_function, frames=np.arange(smoothed_evolution.shape[0]), interval=30)\nanim.save(\"Network evolution smoothed.mp4\")\n\n[01/29/26 13:38:53] INFO     Animation.save using &lt;class 'matplotlib.animation.FFMpegWriter'&gt;     animation.py:1076\n\n\n\n                    INFO     MovieWriter._run: running command: ffmpeg -f rawvideo -vcodec         animation.py:319\n                             rawvideo -s 2000x1000 -pix_fmt rgba -framerate 33.333333333333336                     \n                             -loglevel error -i pipe: -vcodec h264 -pix_fmt yuv420p -y 'Network                    \n                             evolution smoothed.mp4'                                                               \n\n\n\n\n\n\n\n\n\n\n\n\nManim\n\nNUM_LAYERS = 10\nNEURONS_PER_LAYER = 10\nNUM_FRAMES=2000\n\n# --- Simulation\nnetwork = network_init()\nnetwork_states = run_simulation(network, NUM_FRAMES, sigma=1,spont_prob=0.01)\nsmoothed_states = smooth_activity(network_states)\n\n\ndef multilayered_graph(subset_sizes, edge_prob=0.35):\n    ''' Generate a networkx multilayered graph with specied layer sizes '''\n    extents = nx.utils.pairwise(itertools.accumulate([0] + subset_sizes))\n    layers = [range(start, end) for start, end in extents]\n    G = nx.Graph()\n    for (i, layer) in enumerate(layers):\n        G.add_nodes_from(layer, layer=i)\n    for layer1, layer2 in nx.utils.pairwise(layers):\n        all_edges = list(itertools.product(layer1, layer2))\n        selected_edges = np.random.choice(range(len(all_edges)),  size=int(len(all_edges)*edge_prob), replace=False)\n        for k in selected_edges:\n            G.add_edge(*all_edges[k])\n    return G\n\n\nfrom manim import *\nimport networkx as nx\nfrom scipy.interpolate import interp1d\nimport itertools\n\n\n# --- Animation with Manim\nclass BranchingModelRearranging(Scene):\n    def construct(self):\n\n        # Set up coordinate systems\n        shuffled_ax = Axes(x_range=(0,NUM_LAYERS), y_range=(0,NEURONS_PER_LAYER),x_length=7, y_length=7)\n        layers_ax = Axes(x_range=(0,NUM_LAYERS), y_range=(0,NEURONS_PER_LAYER),x_length=13, y_length=7)\n\n        # --- Mapping\n        mapping = np.array(list(itertools.product(range(shuffled_ax.x_range[1]), range(shuffled_ax.y_range[1]))), dtype=object)\n        layout_layered = {k: layers_ax.c2p(*mapping[k]) for k in range(NUM_LAYERS*NEURONS_PER_LAYER)}\n        np.random.shuffle(mapping)\n        layout_shuffle = {k: shuffled_ax.c2p(*mapping[k]) for k in range(NUM_LAYERS*NEURONS_PER_LAYER)}\n\n        # Construct a graph object\n        G = multilayered_graph(([NEURONS_PER_LAYER]*NUM_LAYERS))\n        graph = Graph.from_networkx(G,layout=layout_shuffle,vertex_config={'radius': 0.2},\n                                    edge_config={\"stroke_width\":0.5, \"stroke_color\":GRAY})\n\n        # Interpolation function to animate the color of the nodes according to simulation data\n        value_interp_function = interp1d(np.arange(smoothed_states.shape[0]),\n                                         smoothed_states.reshape(smoothed_states.shape[0], NUM_LAYERS*NEURONS_PER_LAYER), axis=0)\n\n        cmap = cmasher.get_sub_cmap(sns.color_palette(\"mako\",as_cmap=True),0.2,1)\n\n\n        def update_node_colors(graph):\n            for k in range(len(G.nodes)):\n                color =  cmap(value_interp_function(time_tracker.get_value())[k])\n                graph[k].set_color(rgba_to_color(color))\n\n        time_tracker = ValueTracker() # Progressing through simulation data\n        graph.add_updater(update_node_colors)\n        self.add(graph)\n\n        # --- Animating (make sure that there is enough frames in the simulation data)\n        FPS = 30\n        PLAY_TIME_BEFORE_REARRANGING = 20\n        PLAY_TIME_AFTER_REARRANGING = 5\n        REARRANGING_TIME = 2\n\n        def get_shuffle2layered_anims():\n            return [graph[k].animate.move_to(layout_layered[k]) for k in range(len(G.nodes))]\n\n        def animate_network(playing_time):\n            self.play(time_tracker.animate.increment_value(int(playing_time*FPS)), run_time=playing_time, rate_func=linear)\n\n        animate_network(PLAY_TIME_BEFORE_REARRANGING)\n\n\n        self.play(*(get_shuffle2layered_anims() +\n                    [time_tracker.animate.increment_value(int(REARRANGING_TIME*FPS))]),\n                    run_time=REARRANGING_TIME, rate_func=linear)\n\n        animate_network(PLAY_TIME_AFTER_REARRANGING)\n        self.wait()"
  }
]